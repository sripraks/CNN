{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "extract_features.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sripraks/CNN/blob/main/extract_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGfWNPqad9g6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwBhXF5d-4x"
      },
      "source": [
        "Extract Features from VGG16 for flowers data set and train using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP4sPegT0EWJ"
      },
      "source": [
        "# import the necessary packages\n",
        "import h5py\n",
        "import os\n",
        "\n",
        "class HDF5DatasetWriter:\n",
        "\tdef __init__(self, dims, outputPath, dataKey=\"images\",\n",
        "\t\tbufSize=1000):\n",
        "\t\t# check to see if the output path exists, and if so, raise\n",
        "\t\t# an exception\n",
        "\t\tif os.path.exists(outputPath):\n",
        "\t\t\traise ValueError(\"The supplied `outputPath` already \"\n",
        "\t\t\t\t\"exists and cannot be overwritten. Manually delete \"\n",
        "\t\t\t\t\"the file before continuing.\", outputPath)\n",
        "\n",
        "\t\t# open the HDF5 database for writing and create two datasets:\n",
        "\t\t# one to store the images/features and another to store the\n",
        "\t\t# class labels\n",
        "\t\tself.db = h5py.File(outputPath, \"w\")\n",
        "\t\tself.data = self.db.create_dataset(dataKey, dims,\n",
        "\t\t\tdtype=\"float\")\n",
        "\t\tself.labels = self.db.create_dataset(\"labels\", (dims[0],),\n",
        "\t\t\tdtype=\"int\")\n",
        "\n",
        "\t\t# store the buffer size, then initialize the buffer itself\n",
        "\t\t# along with the index into the datasets\n",
        "\t\tself.bufSize = bufSize\n",
        "\t\tself.buffer = {\"data\": [], \"labels\": []}\n",
        "\t\tself.idx = 0\n",
        "\n",
        "\tdef add(self, rows, labels):\n",
        "\t\t# add the rows and labels to the buffer\n",
        "\t\tself.buffer[\"data\"].extend(rows)\n",
        "\t\tself.buffer[\"labels\"].extend(labels)\n",
        "\n",
        "\t\t# check to see if the buffer needs to be flushed to disk\n",
        "\t\tif len(self.buffer[\"data\"]) >= self.bufSize:\n",
        "\t\t\tself.flush()\n",
        "\n",
        "\tdef flush(self):\n",
        "\t\t# write the buffers to disk then reset the buffer\n",
        "\t\ti = self.idx + len(self.buffer[\"data\"])\n",
        "\t\tself.data[self.idx:i] = self.buffer[\"data\"]\n",
        "\t\tself.labels[self.idx:i] = self.buffer[\"labels\"]\n",
        "\t\tself.idx = i\n",
        "\t\tself.buffer = {\"data\": [], \"labels\": []}\n",
        "\n",
        "\tdef storeClassLabels(self, classLabels):\n",
        "\t\t# create a dataset to store the actual class label names,\n",
        "\t\t# then store the class labels\n",
        "\t\tdt = h5py.special_dtype(vlen=str) # `vlen=unicode` for Py2.7\n",
        "\t\tlabelSet = self.db.create_dataset(\"label_names\",\n",
        "\t\t\t(len(classLabels),), dtype=dt)\n",
        "\t\tlabelSet[:] = classLabels\n",
        "\n",
        "\tdef close(self):\n",
        "\t\t# check to see if there are any other entries in the buffer\n",
        "\t\t# that need to be flushed to disk\n",
        "\t\tif len(self.buffer[\"data\"]) > 0:\n",
        "\t\t\tself.flush()\n",
        "\n",
        "\t\t# close the dataset\n",
        "\t\tself.db.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foUVESYpzlbM"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import progressbar\n",
        "import argparse\n",
        "import random\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSEeSrDbzlbP"
      },
      "source": [
        "# store the batch size in a convenience variable\n",
        "bs = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxMJjlp30Ol6",
        "outputId": "5de2a7fc-c4d2-4b26-c4c1-86e26bd7b5e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKz3ex0OzlbR",
        "outputId": "592e93e1-4556-4eff-e19b-25b9d1787eb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# grab the list of images that we'll be describing then randomly\n",
        "# shuffle them to allow for easy training and testing splits via\n",
        "# array slicing during training time\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(\"/content/drive/My Drive/dataset/flowers17/images\"))\n",
        "random.shuffle(imagePaths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1ggPUZAzlbU"
      },
      "source": [
        "# extract the class labels from the image paths then encode the\n",
        "# labels\n",
        "labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPDHyi6JzlbW",
        "outputId": "71279904-0abb-419d-d57b-21af1c3a696b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load the VGG16 network\n",
        "print(\"[INFO] loading network...\")\n",
        "model = VGG16(weights=\"imagenet\", include_top=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading network...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-o1-FeszlbY"
      },
      "source": [
        "# initialize the HDF5 dataset writer, then store the class label\n",
        "# names in the dataset\n",
        "dataset = HDF5DatasetWriter((len(imagePaths), 512 * 7 * 7),\t\"/content/drive/My Drive/dataset/flowers17/hdf5/flowerfeatures.hdf5\", dataKey=\"features\", bufSize=1000)\n",
        "dataset.storeClassLabels(le.classes_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B46lAVyPzlba",
        "outputId": "f8914db4-d808-47e3-b3c3-ef47d611224b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# initialize the progress bar\n",
        "widgets = [\"Extracting Features: \", progressbar.Percentage(), \" \",\n",
        "\tprogressbar.Bar(), \" \", progressbar.ETA()]\n",
        "pbar = progressbar.ProgressBar(maxval=len(imagePaths),\n",
        "\twidgets=widgets).start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rExtracting Features: N/A% |                                    | ETA:  --:--:--"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZDH-OHuzlbc",
        "outputId": "81c34de8-dbe6-432a-8e34-61565bbd9a0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# loop over the images in batches\n",
        "for i in np.arange(0, len(imagePaths), bs):\n",
        "\t# extract the batch of images and labels, then initialize the\n",
        "\t# list of actual images that will be passed through the network\n",
        "\t# for feature extraction\n",
        "\tbatchPaths = imagePaths[i:i + bs]\n",
        "\tbatchLabels = labels[i:i + bs]\n",
        "\tbatchImages = []\n",
        "\n",
        "\t# loop over the images and labels in the current batch\n",
        "\tfor (j, imagePath) in enumerate(batchPaths):\n",
        "\t\t# load the input image using the Keras helper utility\n",
        "\t\t# while ensuring the image is resized to 224x224 pixels\n",
        "\t\timage = load_img(imagePath, target_size=(224, 224))\n",
        "\t\timage = img_to_array(image)\n",
        "\n",
        "\t\t# preprocess the image by (1) expanding the dimensions and\n",
        "\t\t# (2) subtracting the mean RGB pixel intensity from the\n",
        "\t\t# ImageNet dataset\n",
        "\t\timage = np.expand_dims(image, axis=0)\n",
        "\t\timage = imagenet_utils.preprocess_input(image)\n",
        "\n",
        "\t\t# add the image to the batch\n",
        "\t\tbatchImages.append(image)\n",
        "\n",
        "\t# pass the images through the network and use the outputs as\n",
        "\t# our actual features\n",
        "\tbatchImages = np.vstack(batchImages)\n",
        "\tfeatures = model.predict(batchImages, batch_size=bs)\n",
        "\n",
        "\t# reshape the features so that each image is represented by\n",
        "\t# a flattened feature vector of the `MaxPooling2D` outputs\n",
        "\tfeatures = features.reshape((features.shape[0], 512 * 7 * 7))\n",
        "\n",
        "\t# add the features and labels to our HDF5 dataset\n",
        "\tdataset.add(features, batchLabels)\n",
        "\tpbar.update(i)\n",
        "\n",
        "# close the dataset\n",
        "dataset.close()\n",
        "pbar.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting Features: 100% |####################################| Time:  0:13:35\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_HHiaN26CQd"
      },
      "source": [
        "# import the necessary packages\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import argparse\n",
        "import pickle\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsGACQlczlbe"
      },
      "source": [
        "# open the HDF5 database for reading then determine the index of\n",
        "# the training and testing split, provided that this data was\n",
        "# already shuffled *prior* to writing it to disk\n",
        "db = h5py.File(\"/content/drive/My Drive/dataset/flowers17/hdf5/flowerfeatures.hdf5\", \"r\")\n",
        "i = int(db[\"labels\"].shape[0] * 0.75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2v6bAJX5ojv",
        "outputId": "eab4be8a-b83f-4958-d9cc-7a32d2c93dd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# define the set of parameters that we want to tune then start a\n",
        "# grid search where we evaluate our model for each value of C\n",
        "print(\"[INFO] tuning hyperparameters...\")\n",
        "params = {\"C\": [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]}\n",
        "model = GridSearchCV(LogisticRegression(solver=\"lbfgs\",\tmulti_class=\"auto\"), params, cv=3, n_jobs=-1)\n",
        "model.fit(db[\"features\"][:i], db[\"labels\"][:i])\n",
        "print(\"[INFO] best hyperparameters: {}\".format(model.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] tuning hyperparameters...\n",
            "[INFO] best hyperparameters: {'C': 10000.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFspQBKv5uyU",
        "outputId": "f204dc8f-18cd-40e8-87d4-945aa1b5e2b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# evaluate the model\n",
        "print(\"[INFO] evaluating...\")\n",
        "preds = model.predict(db[\"features\"][i:])\n",
        "print(classification_report(db[\"labels\"][i:], preds,target_names=db[\"label_names\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    bluebell       1.00      0.96      0.98        26\n",
            "   buttercup       0.86      0.95      0.90        19\n",
            "   coltsfoot       0.96      0.96      0.96        25\n",
            "     cowslip       0.58      0.92      0.71        12\n",
            "      crocus       0.94      1.00      0.97        17\n",
            "    daffodil       0.94      0.71      0.81        24\n",
            "       daisy       1.00      1.00      1.00        18\n",
            "   dandelion       1.00      0.86      0.92        21\n",
            "  fritillary       0.95      1.00      0.98        21\n",
            "        iris       0.95      1.00      0.97        18\n",
            "  lilyvalley       0.90      0.95      0.93        20\n",
            "       pansy       1.00      0.88      0.94        25\n",
            "    snowdrop       0.95      0.95      0.95        19\n",
            "   sunflower       1.00      1.00      1.00        16\n",
            "   tigerlily       1.00      0.96      0.98        24\n",
            "       tulip       0.54      0.58      0.56        12\n",
            "  windflower       0.96      0.96      0.96        23\n",
            "\n",
            "    accuracy                           0.92       340\n",
            "   macro avg       0.91      0.92      0.91       340\n",
            "weighted avg       0.93      0.92      0.93       340\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSm2P-vj52eM"
      },
      "source": [
        "# close the database\n",
        "db.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}