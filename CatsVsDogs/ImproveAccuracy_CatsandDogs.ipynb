{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImproveAccuracy_CatsandDogs.ipynb",
      "provenance": [],
      "mount_file_id": "1kquSwWb1D2ArIL9_feghOeOqqyO14oTB",
      "authorship_tag": "ABX9TyOPzbGEADmZ+MmDIPoPbFHp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sripraks/CNN/blob/main/ImproveAccuracy_CatsandDogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZJncHG3onvc"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "class ImageToArrayPreprocessor:\n",
        "\tdef __init__(self, dataFormat=None):\n",
        "\t\t# store the image data format\n",
        "\t\tself.dataFormat = dataFormat\n",
        "\n",
        "\tdef preprocess(self, image):\n",
        "\t\t# apply the Keras utility function that correctly rearranges\n",
        "\t\t# the dimensions of the image\n",
        "\t\treturn img_to_array(image, data_format=self.dataFormat)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjAofJg2ot8h"
      },
      "source": [
        "# import the necessary packages\n",
        "import cv2\n",
        "\n",
        "class SimplePreprocessor:\n",
        "\tdef __init__(self, width, height, inter=cv2.INTER_AREA):\n",
        "\t\t# store the target image width, height, and interpolation\n",
        "\t\t# method used when resizing\n",
        "\t\tself.width = width\n",
        "\t\tself.height = height\n",
        "\t\tself.inter = inter\n",
        "\n",
        "\tdef preprocess(self, image):\n",
        "\t\t# resize the image to a fixed size, ignoring the aspect\n",
        "\t\t# ratio\n",
        "\t\treturn cv2.resize(image, (self.width, self.height),\n",
        "\t\t\tinterpolation=self.inter)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sndJU-BaoxCp"
      },
      "source": [
        "# import the necessary packages\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "\n",
        "class PatchPreprocessor:\n",
        "\tdef __init__(self, width, height):\n",
        "\t\t# store the target width and height of the image\n",
        "\t\tself.width = width\n",
        "\t\tself.height = height\n",
        "\n",
        "\tdef preprocess(self, image):\n",
        "\t\t# extract a random crop from the image with the target width\n",
        "\t\t# and height\n",
        "\t\treturn extract_patches_2d(image, (self.height, self.width),\n",
        "\t\t\tmax_patches=1)[0]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4HaVIEDoz8Z"
      },
      "source": [
        "# import the necessary packages\n",
        "import cv2\n",
        "\n",
        "class MeanPreprocessor:\n",
        "\tdef __init__(self, rMean, gMean, bMean):\n",
        "\t\t# store the Red, Green, and Blue channel averages across a\n",
        "\t\t# training set\n",
        "\t\tself.rMean = rMean\n",
        "\t\tself.gMean = gMean\n",
        "\t\tself.bMean = bMean\n",
        "\n",
        "\tdef preprocess(self, image):\n",
        "\t\t# split the image into its respective Red, Green, and Blue\n",
        "\t\t# channels\n",
        "\t\t(B, G, R) = cv2.split(image.astype(\"float32\"))\n",
        "\n",
        "\t\t# subtract the means for each channel\n",
        "\t\tR -= self.rMean\n",
        "\t\tG -= self.gMean\n",
        "\t\tB -= self.bMean\n",
        "\n",
        "\t\t# merge the channels back together and return the image\n",
        "\t\treturn cv2.merge([B, G, R])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhZT79HGo8H5"
      },
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "class CropPreprocessor:\n",
        "\tdef __init__(self, width, height, horiz=True, inter=cv2.INTER_AREA):\n",
        "\t\t# store the target image width, height, whether or not\n",
        "\t\t# horizontal flips should be included, along with the\n",
        "\t\t# interpolation method used when resizing\n",
        "\t\tself.width = width\n",
        "\t\tself.height = height\n",
        "\t\tself.horiz = horiz\n",
        "\t\tself.inter = inter\n",
        "\n",
        "\tdef preprocess(self, image):\n",
        "\t\t# initialize the list of crops\n",
        "\t\tcrops = []\n",
        "\n",
        "\t\t# grab the width and height of the image then use these\n",
        "\t\t# dimensions to define the corners of the image based\n",
        "\t\t(h, w) = image.shape[:2]\n",
        "\t\tcoords = [\n",
        "\t\t\t[0, 0, self.width, self.height],\n",
        "\t\t\t[w - self.width, 0, w, self.height],\n",
        "\t\t\t[w - self.width, h - self.height, w, h],\n",
        "\t\t\t[0, h - self.height, self.width, h]]\n",
        "\n",
        "\t\t# compute the center crop of the image as well\n",
        "\t\tdW = int(0.5 * (w - self.width))\n",
        "\t\tdH = int(0.5 * (h - self.height))\n",
        "\t\tcoords.append([dW, dH, w - dW, h - dH])\n",
        "\n",
        "\t\t# loop over the coordinates, extract each of the crops,\n",
        "\t\t# and resize each of them to a fixed size\n",
        "\t\tfor (startX, startY, endX, endY) in coords:\n",
        "\t\t\tcrop = image[startY:endY, startX:endX]\n",
        "\t\t\tcrop = cv2.resize(crop, (self.width, self.height),\n",
        "\t\t\t\tinterpolation=self.inter)\n",
        "\t\t\tcrops.append(crop)\n",
        "\n",
        "\t\t# check to see if the horizontal flips should be taken\n",
        "\t\tif self.horiz:\n",
        "\t\t\t# compute the horizontal mirror flips for each crop\n",
        "\t\t\tmirrors = [cv2.flip(c, 1) for c in crops]\n",
        "\t\t\tcrops.extend(mirrors)\n",
        "\n",
        "\t\t# return the set of crops\n",
        "\t\treturn np.array(crops)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "354SB4NJpFrr"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "class HDF5DatasetGenerator:\n",
        "\tdef __init__(self, dbPath, batchSize, preprocessors=None,\n",
        "\t\taug=None, binarize=True, classes=2):\n",
        "\t\t# store the batch size, preprocessors, and data augmentor,\n",
        "\t\t# whether or not the labels should be binarized, along with\n",
        "\t\t# the total number of classes\n",
        "\t\tself.batchSize = batchSize\n",
        "\t\tself.preprocessors = preprocessors\n",
        "\t\tself.aug = aug\n",
        "\t\tself.binarize = binarize\n",
        "\t\tself.classes = classes\n",
        "\n",
        "\t\t# open the HDF5 database for reading and determine the total\n",
        "\t\t# number of entries in the database\n",
        "\t\tself.db = h5py.File(dbPath, \"r\")\n",
        "\t\tself.numImages = self.db[\"labels\"].shape[0]\n",
        "\n",
        "\tdef generator(self, passes=np.inf):\n",
        "\t\t# initialize the epoch count\n",
        "\t\tepochs = 0\n",
        "\n",
        "\t\t# keep looping infinitely -- the model will stop once we have\n",
        "\t\t# reach the desired number of epochs\n",
        "\t\twhile epochs < passes:\n",
        "\t\t\t# loop over the HDF5 dataset\n",
        "\t\t\tfor i in np.arange(0, self.numImages, self.batchSize):\n",
        "\t\t\t\t# extract the images and labels from the HDF dataset\n",
        "\t\t\t\timages = self.db[\"images\"][i: i + self.batchSize]\n",
        "\t\t\t\tlabels = self.db[\"labels\"][i: i + self.batchSize]\n",
        "\n",
        "\t\t\t\t# check to see if the labels should be binarized\n",
        "\t\t\t\tif self.binarize:\n",
        "\t\t\t\t\tlabels = to_categorical(labels,\n",
        "\t\t\t\t\t\tself.classes)\n",
        "\n",
        "\t\t\t\t# check to see if our preprocessors are not None\n",
        "\t\t\t\tif self.preprocessors is not None:\n",
        "\t\t\t\t\t# initialize the list of processed images\n",
        "\t\t\t\t\tprocImages = []\n",
        "\n",
        "\t\t\t\t\t# loop over the images\n",
        "\t\t\t\t\tfor image in images:\n",
        "\t\t\t\t\t\t# loop over the preprocessors and apply each\n",
        "\t\t\t\t\t\t# to the image\n",
        "\t\t\t\t\t\tfor p in self.preprocessors:\n",
        "\t\t\t\t\t\t\timage = p.preprocess(image)\n",
        "\n",
        "\t\t\t\t\t\t# update the list of processed images\n",
        "\t\t\t\t\t\tprocImages.append(image)\n",
        "\n",
        "\t\t\t\t\t# update the images array to be the processed\n",
        "\t\t\t\t\t# images\n",
        "\t\t\t\t\timages = np.array(procImages)\n",
        "\n",
        "\t\t\t\t# if the data augmenator exists, apply it\n",
        "\t\t\t\tif self.aug is not None:\n",
        "\t\t\t\t\t(images, labels) = next(self.aug.flow(images,\n",
        "\t\t\t\t\t\tlabels, batch_size=self.batchSize))\n",
        "\n",
        "\t\t\t\t# yield a tuple of images and labels\n",
        "\t\t\t\tyield (images, labels)\n",
        "\n",
        "\t\t\t# increment the total number of epochs\n",
        "\t\t\tepochs += 1\n",
        "\n",
        "\tdef close(self):\n",
        "\t\t# close the database\n",
        "\t\tself.db.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnp8xcnQpK5r"
      },
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "\n",
        "def rank5_accuracy(preds, labels):\n",
        "\t# initialize the rank-1 and rank-5 accuracies\n",
        "\trank1 = 0\n",
        "\trank5 = 0\n",
        "\n",
        "\t# loop over the predictions and ground-truth labels\n",
        "\tfor (p, gt) in zip(preds, labels):\n",
        "\t\t# sort the probabilities by their index in descending\n",
        "\t\t# order so that the more confident guesses are at the\n",
        "\t\t# front of the list\n",
        "\t\tp = np.argsort(p)[::-1]\n",
        "\n",
        "\t\t# check if the ground-truth label is in the top-5\n",
        "\t\t# predictions\n",
        "\t\tif gt in p[:5]:\n",
        "\t\t\trank5 += 1\n",
        "\n",
        "\t\t# check to see if the ground-truth is the #1 prediction\n",
        "\t\tif gt == p[0]:\n",
        "\t\t\trank1 += 1\n",
        "\n",
        "\t# compute the final rank-1 and rank-5 accuracies\n",
        "\trank1 /= float(len(preds))\n",
        "\trank5 /= float(len(preds))\n",
        "\n",
        "\t# return a tuple of the rank-1 and rank-5 accuracies\n",
        "\treturn (rank1, rank5)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l0QaWFjpS8p"
      },
      "source": [
        "# define the paths to the images directory\n",
        "IMAGES_PATH = \"/content/drive/MyDrive/dataset/catsanddogs/train\"\n",
        "\n",
        "# since we do not have validation data or access to the testing\n",
        "# labels we need to take a number of images from the training\n",
        "# data and use them instead\n",
        "NUM_CLASSES = 2\n",
        "NUM_VAL_IMAGES = 100 * NUM_CLASSES\n",
        "NUM_TEST_IMAGES = 100 * NUM_CLASSES\n",
        "\n",
        "# define the path to the output training, validation, and testing\n",
        "# HDF5 files\n",
        "TRAIN_HDF5 = \"/content/drive/MyDrive/dataset/catsanddogs/train/hdf5/train.hdf5\"\n",
        "VAL_HDF5 = \"/content/drive/MyDrive/dataset/catsanddogs/train/hdf5/val.hdf5\"\n",
        "TEST_HDF5 = \"/content/drive/MyDrive/dataset/catsanddogs/train/hdf5/test.hdf5\"\n",
        "\n",
        "# path to the output model file\n",
        "MODEL_PATH = \"/content/drive/MyDrive/dataset/catsanddogs/train/output/alexnet_dogs_vs_cats.model\"\n",
        "\n",
        "# define the path to the dataset mean\n",
        "DATASET_MEAN = \"/content/drive/MyDrive/dataset/catsanddogs/train/output/dogs_vs_cats_mean.json\"\n",
        "\n",
        "# define the path to the output directory used for storing plots,\n",
        "# classification reports, etc.\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/dataset/catsanddogs/train/output\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJh-HqA4pdzZ"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import progressbar\n",
        "import json"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLjK6xsxpiox"
      },
      "source": [
        "# load the RGB means for the training set\n",
        "means = json.loads(open(DATASET_MEAN).read())\n",
        "# initialize the image preprocessors\n",
        "sp = SimplePreprocessor(227, 227)\n",
        "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
        "cp = CropPreprocessor(227, 227)\n",
        "iap = ImageToArrayPreprocessor()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt0yThaRpkX7",
        "outputId": "add6b75f-46e3-4385-eaa6-5fc5194944b0"
      },
      "source": [
        "# load the pretrained network\n",
        "print(\"[INFO] loading model...\")\n",
        "model = load_model(MODEL_PATH)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAea7ZK4pmQw",
        "outputId": "3a28f511-a9d5-451d-9e94-7100fc61203f"
      },
      "source": [
        "# initialize the testing dataset generator, then make predictions on\n",
        "# the testing data\n",
        "print(\"[INFO] predicting on test data (no crops)...\")\n",
        "testGen = HDF5DatasetGenerator(TEST_HDF5, 64,preprocessors=[sp, mp, iap], classes=2)\n",
        "predictions = model.predict_generator(testGen.generator(),steps=testGen.numImages // 64, max_queue_size=10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] predicting on test data (no crops)...\n",
            "WARNING:tensorflow:From <ipython-input-14-daa1bb8bb745>:5: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlTZK7r9posx",
        "outputId": "3e5da352-101c-41b7-e12d-60ff87765dc1"
      },
      "source": [
        "# compute the rank-1 and rank-5 accuracies\n",
        "(rank1, _) = rank5_accuracy(predictions, testGen.db[\"labels\"])\n",
        "print(\"[INFO] rank-1: {:.2f}%\".format(rank1 * 100))\n",
        "testGen.close()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] rank-1: 63.02%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GklL7myjpqUJ"
      },
      "source": [
        "# re-initialize the testing set generator, this time excluding the\n",
        "# `SimplePreprocessor`\n",
        "testGen = HDF5DatasetGenerator(TEST_HDF5, 64,preprocessors=[mp], classes=2)\n",
        "predictions = []"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTmleNoppr9w",
        "outputId": "1775dc53-9447-48f7-c199-96a9925bce4f"
      },
      "source": [
        "# initialize the progress bar\n",
        "widgets = [\"Evaluating: \", progressbar.Percentage(), \" \",\n",
        "\tprogressbar.Bar(), \" \", progressbar.ETA()]\n",
        "pbar = progressbar.ProgressBar(maxval=testGen.numImages // 64,\n",
        "\twidgets=widgets).start()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rEvaluating: N/A% |                                             | ETA:  --:--:--"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJWgyz-ypuJw",
        "outputId": "456066e6-b13d-4dc1-9c0b-fb2b6ad4ee29"
      },
      "source": [
        "# loop over a single pass of the test data\n",
        "for (i, (images, labels)) in enumerate(testGen.generator(passes=1)):\n",
        "\t# loop over each of the individual images\n",
        "\tfor image in images:\n",
        "\t\t# apply the crop preprocessor to the image to generate 10\n",
        "\t\t# separate crops, then convert them from images to arrays\n",
        "\t\tcrops = cp.preprocess(image)\n",
        "\t\tcrops = np.array([iap.preprocess(c) for c in crops],\n",
        "\t\t\tdtype=\"float32\")\n",
        "\n",
        "\t\t# make predictions on the crops and then average them\n",
        "\t\t# together to obtain the final prediction\n",
        "\t\tpred = model.predict(crops)\n",
        "\t\tpredictions.append(pred.mean(axis=0))\n",
        "\n",
        "\t# update the progress bar\n",
        "\tpbar.update(i)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating: 100% |#############################################| ETA:  00:00:00"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6-yYlKspv6Z",
        "outputId": "07b6a1b0-02e1-41c7-f3d6-0590e585e3c9"
      },
      "source": [
        "# compute the rank-1 accuracy\n",
        "pbar.finish()\n",
        "print(\"[INFO] predicting on test data (with crops)...\")\n",
        "(rank1, _) = rank5_accuracy(predictions, testGen.db[\"labels\"])\n",
        "print(\"[INFO] rank-1: {:.2f}%\".format(rank1 * 100))\n",
        "testGen.close()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rEvaluating: 100% |#############################################| Time:  0:02:23\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] predicting on test data (with crops)...\n",
            "[INFO] rank-1: 63.00%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
