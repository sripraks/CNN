{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "build_dogs_vs_cats.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sripraks/CNN/blob/main/build_dogs_vs_cats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX2-deUgVqdk"
      },
      "source": [
        "# import the necessary packages\n",
        "import imutils\n",
        "import cv2\n",
        "\n",
        "class AspectAwarePreprocessor:\n",
        "\tdef __init__(self, width, height, inter=cv2.INTER_AREA):\n",
        "\t\t# store the target image width, height, and interpolation\n",
        "\t\t# method used when resizing\n",
        "\t\tself.width = width\n",
        "\t\tself.height = height\n",
        "\t\tself.inter = inter\n",
        "\n",
        "\tdef preprocess(self, image):\n",
        "\t\t# grab the dimensions of the image and then initialize\n",
        "\t\t# the deltas to use when cropping\n",
        "\t\t(h, w) = image.shape[:2]\n",
        "\t\tdW = 0\n",
        "\t\tdH = 0\n",
        "\n",
        "\t\t# if the width is smaller than the height, then resize\n",
        "\t\t# along the width (i.e., the smaller dimension) and then\n",
        "\t\t# update the deltas to crop the height to the desired\n",
        "\t\t# dimension\n",
        "\t\tif w < h:\n",
        "\t\t\timage = imutils.resize(image, width=self.width,\n",
        "\t\t\t\tinter=self.inter)\n",
        "\t\t\tdH = int((image.shape[0] - self.height) / 2.0)\n",
        "\n",
        "\t\t# otherwise, the height is smaller than the width so\n",
        "\t\t# resize along the height and then update the deltas\n",
        "\t\t# crop along the width\n",
        "\t\telse:\n",
        "\t\t\timage = imutils.resize(image, height=self.height,\n",
        "\t\t\t\tinter=self.inter)\n",
        "\t\t\tdW = int((image.shape[1] - self.width) / 2.0)\n",
        "\n",
        "\t\t# now that our images have been resized, we need to\n",
        "\t\t# re-grab the width and height, followed by performing\n",
        "\t\t# the crop\n",
        "\t\t(h, w) = image.shape[:2]\n",
        "\t\timage = image[dH:h - dH, dW:w - dW]\n",
        "\n",
        "\t\t# finally, resize the image to the provided spatial\n",
        "\t\t# dimensions to ensure our output image is always a fixed\n",
        "\t\t# size\n",
        "\t\treturn cv2.resize(image, (self.width, self.height),\n",
        "\t\t\tinterpolation=self.inter)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkAExv_AVyiU"
      },
      "source": [
        "# import the necessary packages\n",
        "import h5py\n",
        "import os\n",
        "\n",
        "class HDF5DatasetWriter:\n",
        "\tdef __init__(self, dims, outputPath, dataKey=\"images\",\n",
        "\t\tbufSize=1000):\n",
        "\t\t# check to see if the output path exists, and if so, raise\n",
        "\t\t# an exception\n",
        "\t\tif os.path.exists(outputPath):\n",
        "\t\t\traise ValueError(\"The supplied `outputPath` already \"\n",
        "\t\t\t\t\"exists and cannot be overwritten. Manually delete \"\n",
        "\t\t\t\t\"the file before continuing.\", outputPath)\n",
        "\n",
        "\t\t# open the HDF5 database for writing and create two datasets:\n",
        "\t\t# one to store the images/features and another to store the\n",
        "\t\t# class labels\n",
        "\t\tself.db = h5py.File(outputPath, \"w\")\n",
        "\t\tself.data = self.db.create_dataset(dataKey, dims,\n",
        "\t\t\tdtype=\"float\")\n",
        "\t\tself.labels = self.db.create_dataset(\"labels\", (dims[0],),\n",
        "\t\t\tdtype=\"int\")\n",
        "\n",
        "\t\t# store the buffer size, then initialize the buffer itself\n",
        "\t\t# along with the index into the datasets\n",
        "\t\tself.bufSize = bufSize\n",
        "\t\tself.buffer = {\"data\": [], \"labels\": []}\n",
        "\t\tself.idx = 0\n",
        "\n",
        "\tdef add(self, rows, labels):\n",
        "\t\t# add the rows and labels to the buffer\n",
        "\t\tself.buffer[\"data\"].extend(rows)\n",
        "\t\tself.buffer[\"labels\"].extend(labels)\n",
        "\n",
        "\t\t# check to see if the buffer needs to be flushed to disk\n",
        "\t\tif len(self.buffer[\"data\"]) >= self.bufSize:\n",
        "\t\t\tself.flush()\n",
        "\n",
        "\tdef flush(self):\n",
        "\t\t# write the buffers to disk then reset the buffer\n",
        "\t\ti = self.idx + len(self.buffer[\"data\"])\n",
        "\t\tself.data[self.idx:i] = self.buffer[\"data\"]\n",
        "\t\tself.labels[self.idx:i] = self.buffer[\"labels\"]\n",
        "\t\tself.idx = i\n",
        "\t\tself.buffer = {\"data\": [], \"labels\": []}\n",
        "\n",
        "\tdef storeClassLabels(self, classLabels):\n",
        "\t\t# create a dataset to store the actual class label names,\n",
        "\t\t# then store the class labels\n",
        "\t\tdt = h5py.special_dtype(vlen=str) # `vlen=unicode` for Py2.7\n",
        "\t\tlabelSet = self.db.create_dataset(\"label_names\",\n",
        "\t\t\t(len(classLabels),), dtype=dt)\n",
        "\t\tlabelSet[:] = classLabels\n",
        "\n",
        "\tdef close(self):\n",
        "\t\t# check to see if there are any other entries in the buffer\n",
        "\t\t# that need to be flushed to disk\n",
        "\t\tif len(self.buffer[\"data\"]) > 0:\n",
        "\t\t\tself.flush()\n",
        "\n",
        "\t\t# close the dataset\n",
        "\t\tself.db.close()"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1S6008YWG5e",
        "outputId": "966991bc-3f4d-40bc-cd7d-885b58ec1567"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV4YN-4dWCMr"
      },
      "source": [
        "# define the paths to the images directory\n",
        "IMAGES_PATH = \"/content/drive/MyDrive/dataset/catsanddogs/train\"\n",
        "\n",
        "# since we do not have validation data or access to the testing\n",
        "# labels we need to take a number of images from the training\n",
        "# data and use them instead\n",
        "NUM_CLASSES = 2\n",
        "NUM_VAL_IMAGES = 100 * NUM_CLASSES\n",
        "NUM_TEST_IMAGES = 100 * NUM_CLASSES\n",
        "\n",
        "# define the path to the output training, validation, and testing\n",
        "# HDF5 files\n",
        "TRAIN_HDF5 = \"/content/drive/MyDrive/dataset/catsanddogs/train/hdf5/train.hdf5\"\n",
        "VAL_HDF5 = \"/content/drive/MyDrive/dataset/catsanddogs/train/hdf5/val.hdf5\"\n",
        "TEST_HDF5 = \"/content/drive/MyDrive/dataset/catsanddogs/train/hdf5/test.hdf5\"\n",
        "\n",
        "# path to the output model file\n",
        "MODEL_PATH = \"/content/drive/MyDrive/dataset/catsanddogs/train/output/alexnet_dogs_vs_cats.model\"\n",
        "\n",
        "# define the path to the dataset mean\n",
        "DATASET_MEAN = \"/content/drive/MyDrive/dataset/catsanddogs/train/output/dogs_vs_cats_mean.json\"\n",
        "\n",
        "# define the path to the output directory used for storing plots,\n",
        "# classification reports, etc.\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/dataset/catsanddogs/train/output\""
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAYd3Vg2Vgmm"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import progressbar\n",
        "import json\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQdwEixlVgmn"
      },
      "source": [
        "# grab the paths to the images\n",
        "trainPaths = list(paths.list_images(IMAGES_PATH))\n",
        "trainLabels = [p.split(os.path.sep)[-1].split(\".\")[0] for p in trainPaths]\n",
        "le = LabelEncoder()\n",
        "trainLabels = le.fit_transform(trainLabels)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcg1p-LzVgmn",
        "outputId": "4a2d9285-1142-4e4f-b601-e01a2ebdfa86"
      },
      "source": [
        "len(trainPaths)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uniNJCoTVgmo"
      },
      "source": [
        "# perform stratified sampling from the training set to build the\n",
        "# testing split from the training data\n",
        "split = train_test_split(trainPaths, trainLabels,test_size=NUM_TEST_IMAGES, stratify=trainLabels,random_state=42)\n",
        "(trainPaths, testPaths, trainLabels, testLabels) = split"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Ty3vD2YW9i",
        "outputId": "25f291b8-9992-493d-8889-8bc902265495"
      },
      "source": [
        "print(len(trainPaths))\n",
        "print(len(testPaths))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1802\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NWJnPhNVgmo"
      },
      "source": [
        "# perform another stratified sampling, this time to build the\n",
        "# validation data\n",
        "split = train_test_split(trainPaths, trainLabels,test_size=NUM_VAL_IMAGES, stratify=trainLabels,random_state=42)\n",
        "(trainPaths, valPaths, trainLabels, valLabels) = split"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SSWnlXVaKKp",
        "outputId": "4a53293e-de43-48ae-b3ef-81dcf7586ab7"
      },
      "source": [
        "print(len(trainPaths))\n",
        "print(len(valPaths))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1602\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp2kvYtLVgmo"
      },
      "source": [
        "# construct a list pairing the training, validation, and testing\n",
        "# image paths along with their corresponding labels and output HDF5\n",
        "# files\n",
        "datasets = [(\"train\", trainPaths, trainLabels, TRAIN_HDF5),(\"val\", valPaths, valLabels, VAL_HDF5),(\"test\", testPaths, testLabels, TEST_HDF5)]"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkjDs_SqVgmo"
      },
      "source": [
        "# initialize the image pre-processor and the lists of RGB channel\n",
        "# averages\n",
        "aap = AspectAwarePreprocessor(256, 256)\n",
        "(R, G, B) = ([], [], [])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSX1svmbVgmo",
        "outputId": "7f6e9535-958a-46fa-9df1-f5c0c69274e9"
      },
      "source": [
        "# loop over the dataset tuples\n",
        "for (dType, paths, labels, outputPath) in datasets:\n",
        "\t# create HDF5 writer\n",
        "\tprint(\"[INFO] building {}...\".format(outputPath))\n",
        "\twriter = HDF5DatasetWriter((len(paths), 256, 256, 3), outputPath)\n",
        "\n",
        "\t# initialize the progress bar\n",
        "\twidgets = [\"Building Dataset: \", progressbar.Percentage(), \" \",\n",
        "\t\tprogressbar.Bar(), \" \", progressbar.ETA()]\n",
        "\tpbar = progressbar.ProgressBar(maxval=len(paths),\n",
        "\t\twidgets=widgets).start()\n",
        "\n",
        "\t# loop over the image paths\n",
        "\tfor (i, (path, label)) in enumerate(zip(paths, labels)):\n",
        "\t\t# load the image and process it\n",
        "\t\timage = cv2.imread(path)\n",
        "\t\timage = aap.preprocess(image)\n",
        "\n",
        "\t\t# if we are building the training dataset, then compute the\n",
        "\t\t# mean of each channel in the image, then update the\n",
        "\t\t# respective lists\n",
        "\t\tif dType == \"train\":\n",
        "\t\t\t(b, g, r) = cv2.mean(image)[:3]\n",
        "\t\t\tR.append(r)\n",
        "\t\t\tG.append(g)\n",
        "\t\t\tB.append(b)\n",
        "\n",
        "\t\t# add the image and label # to the HDF5 dataset\n",
        "\t\twriter.add([image], [label])\n",
        "\t\tpbar.update(i)\n",
        "\n",
        "\t# close the HDF5 writer\n",
        "\tpbar.finish()\n",
        "\twriter.close()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rBuilding Dataset: N/A% |                                       | ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] building /content/drive/MyDrive/dataset/catsanddogs/train/hdf5/train.hdf5...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Building Dataset: 100% |#######################################| Time:  0:05:22\n",
            "Building Dataset: N/A% |                                       | ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] building /content/drive/MyDrive/dataset/catsanddogs/train/hdf5/val.hdf5...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Building Dataset: 100% |#######################################| Time:  0:00:39\n",
            "Building Dataset: N/A% |                                       | ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] building /content/drive/MyDrive/dataset/catsanddogs/train/hdf5/test.hdf5...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Building Dataset: 100% |#######################################| Time:  0:00:37\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybWpzHXLVgmo",
        "outputId": "f696f173-d6ab-41e8-9cfb-20a84395a4b3"
      },
      "source": [
        "# construct a dictionary of averages, then serialize the means to a\n",
        "# JSON file\n",
        "print(\"[INFO] serializing means...\")\n",
        "D = {\"R\": np.mean(R), \"G\": np.mean(G), \"B\": np.mean(B)}\n",
        "f = open(DATASET_MEAN, \"w\")\n",
        "f.write(json.dumps(D))\n",
        "f.close()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] serializing means...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG-wQFPMVgmo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
