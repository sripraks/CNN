{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_tinyImageNet-200.ipynb",
      "provenance": [],
      "mount_file_id": "1dNNunUnDiwmJtS7TTf4gbqBMFNrknPIf",
      "authorship_tag": "ABX9TyNel+C7bQugXnSCN7J9okbv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sripraks/CNN/blob/main/tinyImageNet-200/Train_tinyImageNet_200_Expriment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldr9o-_M266K"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from os import path\r\n",
        "\r\n",
        "# define the paths to the training and validation directories\r\n",
        "TRAIN_IMAGES = \"/content/drive/MyDrive/dataset/tiny-imagenet-200\"\r\n",
        "VAL_IMAGES = \"/content/drive/MyDrive/dataset/tiny-imagenet-200/val\"\r\n",
        "\r\n",
        "# define the path to the file that maps validation filenames to\r\n",
        "# their corresponding class labels\r\n",
        "VAL_MAPPINGS = \"/content/drive/MyDrive/dataset/tiny-imagenet-200/val/val_annotations.txt\"\r\n",
        "\r\n",
        "# define the paths to the WordNet hierarchy files which are used\r\n",
        "# to generate our class labels\r\n",
        "WORDNET_IDS = \"/content/drive/MyDrive/dataset/tiny-imagenet-200/wnids.txt\"\r\n",
        "WORD_LABELS = \"/content/drive/MyDrive/dataset/tiny-imagenet-200/words.txt\"\r\n",
        "\r\n",
        "# since we do not have access to the testing data we need to\r\n",
        "# take a number of images from the training data and use it instead\r\n",
        "NUM_CLASSES = 200\r\n",
        "NUM_TEST_IMAGES = 50 * NUM_CLASSES\r\n",
        "\r\n",
        "# define the path to the output training, validation, and testing\r\n",
        "# HDF5 files\r\n",
        "TRAIN_HDF5 = \"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/train.hdf5\"\r\n",
        "VAL_HDF5 = \"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/val.hdf5\"\r\n",
        "TEST_HDF5 = \"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/test.hdf5\"\r\n",
        "\r\n",
        "# define the path to the dataset mean\r\n",
        "DATASET_MEAN = \"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/output/tiny-image-net-200-mean.json\"\r\n",
        "\r\n",
        "# define the path to the output directory used for storing plots,\r\n",
        "# classification reports, etc.\r\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/output\"\r\n",
        "MODEL_PATH = path.sep.join([OUTPUT_PATH,\"checkpoints\", \"epoch_70.hdf5\"])\r\n",
        "FIG_PATH = path.sep.join([OUTPUT_PATH,\"deepergooglenet_tinyimagenet.png\"])\r\n",
        "JSON_PATH = path.sep.join([OUTPUT_PATH,\"deepergooglenet_tinyimagenet.json\"])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9m0pqrI3ljX"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\r\n",
        "\r\n",
        "class ImageToArrayPreprocessor:\r\n",
        "\tdef __init__(self, dataFormat=None):\r\n",
        "\t\t# store the image data format\r\n",
        "\t\tself.dataFormat = dataFormat\r\n",
        "\r\n",
        "\tdef preprocess(self, image):\r\n",
        "\t\t# apply the Keras utility function that correctly rearranges\r\n",
        "\t\t# the dimensions of the image\r\n",
        "\t\treturn img_to_array(image, data_format=self.dataFormat)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5thPCJi3sjV"
      },
      "source": [
        "# import the necessary packages\r\n",
        "import cv2\r\n",
        "\r\n",
        "class SimplePreprocessor:\r\n",
        "\tdef __init__(self, width, height, inter=cv2.INTER_AREA):\r\n",
        "\t\t# store the target image width, height, and interpolation\r\n",
        "\t\t# method used when resizing\r\n",
        "\t\tself.width = width\r\n",
        "\t\tself.height = height\r\n",
        "\t\tself.inter = inter\r\n",
        "\r\n",
        "\tdef preprocess(self, image):\r\n",
        "\t\t# resize the image to a fixed size, ignoring the aspect\r\n",
        "\t\t# ratio\r\n",
        "\t\treturn cv2.resize(image, (self.width, self.height),interpolation=self.inter)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8ykqu-732p4"
      },
      "source": [
        "# import the necessary packages\r\n",
        "import cv2\r\n",
        "\r\n",
        "class MeanPreprocessor:\r\n",
        "\tdef __init__(self, rMean, gMean, bMean):\r\n",
        "\t\t# store the Red, Green, and Blue channel averages across a\r\n",
        "\t\t# training set\r\n",
        "\t\tself.rMean = rMean\r\n",
        "\t\tself.gMean = gMean\r\n",
        "\t\tself.bMean = bMean\r\n",
        "\r\n",
        "\tdef preprocess(self, image):\r\n",
        "\t\t# split the image into its respective Red, Green, and Blue\r\n",
        "\t\t# channels\r\n",
        "\t\t(B, G, R) = cv2.split(image.astype(\"float32\"))\r\n",
        "\r\n",
        "\t\t# subtract the means for each channel\r\n",
        "\t\tR -= self.rMean\r\n",
        "\t\tG -= self.gMean\r\n",
        "\t\tB -= self.bMean\r\n",
        "\r\n",
        "\t\t# merge the channels back together and return the image\r\n",
        "\t\treturn cv2.merge([B, G, R])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVPsrqIh3_YD"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.callbacks import Callback\r\n",
        "import os\r\n",
        "\r\n",
        "class EpochCheckpoint(Callback):\r\n",
        "\tdef __init__(self, outputPath, every=5, startAt=0):\r\n",
        "\t\t# call the parent constructor\r\n",
        "\t\tsuper(Callback, self).__init__()\r\n",
        "\r\n",
        "\t\t# store the base output path for the model, the number of\r\n",
        "\t\t# epochs that must pass before the model is serialized to\r\n",
        "\t\t# disk and the current epoch value\r\n",
        "\t\tself.outputPath = outputPath\r\n",
        "\t\tself.every = every\r\n",
        "\t\tself.intEpoch = startAt\r\n",
        "\r\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\r\n",
        "\t\t# check to see if the model should be serialized to disk\r\n",
        "\t\tif (self.intEpoch + 1) % self.every == 0:\r\n",
        "\t\t\tp = os.path.sep.join([self.outputPath,\"epoch_{}.hdf5\".format(self.intEpoch + 1)])\r\n",
        "\t\t\tself.model.save(p, overwrite=True)\r\n",
        "\r\n",
        "\t\t# increment the internal epoch counter\r\n",
        "\t\tself.intEpoch += 1"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf7vh4J54FTD"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.callbacks import BaseLogger\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import os\r\n",
        "\r\n",
        "class TrainingMonitor(BaseLogger):\r\n",
        "\tdef __init__(self, figPath, jsonPath=None, startAt=0):\r\n",
        "\t\t# store the output path for the figure, the path to the JSON\r\n",
        "\t\t# serialized file, and the starting epoch\r\n",
        "\t\tsuper(TrainingMonitor, self).__init__()\r\n",
        "\t\tself.figPath = figPath\r\n",
        "\t\tself.jsonPath = jsonPath\r\n",
        "\t\tself.startAt = startAt\r\n",
        "\r\n",
        "\tdef on_train_begin(self, logs={}):\r\n",
        "\t\t# initialize the history dictionary\r\n",
        "\t\tself.H = {}\r\n",
        "\r\n",
        "\t\t# if the JSON history path exists, load the training history\r\n",
        "\t\tif self.jsonPath is not None:\r\n",
        "\t\t\tif os.path.exists(self.jsonPath):\r\n",
        "\t\t\t\tself.H = json.loads(open(self.jsonPath).read())\r\n",
        "\r\n",
        "\t\t\t\t# check to see if a starting epoch was supplied\r\n",
        "\t\t\t\tif self.startAt > 0:\r\n",
        "\t\t\t\t\t# loop over the entries in the history log and\r\n",
        "\t\t\t\t\t# trim any entries that are past the starting\r\n",
        "\t\t\t\t\t# epoch\r\n",
        "\t\t\t\t\tfor k in self.H.keys():\r\n",
        "\t\t\t\t\t\tself.H[k] = self.H[k][:self.startAt]\r\n",
        "\r\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\r\n",
        "\t\t# loop over the logs and update the loss, accuracy, etc.\r\n",
        "\t\t# for the entire training process\r\n",
        "\t\tfor (k, v) in logs.items():\r\n",
        "\t\t\tl = self.H.get(k, [])\r\n",
        "\t\t\tl.append(float(v))\r\n",
        "\t\t\tself.H[k] = l\r\n",
        "\r\n",
        "\t\t# check to see if the training history should be serialized\r\n",
        "\t\t# to file\r\n",
        "\t\tif self.jsonPath is not None:\r\n",
        "\t\t\tf = open(self.jsonPath, \"w\")\r\n",
        "\t\t\tf.write(json.dumps(self.H))\r\n",
        "\t\t\tf.close()\r\n",
        "\r\n",
        "\t\t# ensure at least two epochs have passed before plotting\r\n",
        "\t\t# (epoch starts at zero)\r\n",
        "\t\tif len(self.H[\"loss\"]) > 1:\r\n",
        "\t\t\t# plot the training loss and accuracy\r\n",
        "\t\t\tN = np.arange(0, len(self.H[\"loss\"]))\r\n",
        "\t\t\tplt.style.use(\"ggplot\")\r\n",
        "\t\t\tplt.figure()\r\n",
        "\t\t\tplt.plot(N, self.H[\"loss\"], label=\"train_loss\")\r\n",
        "\t\t\tplt.plot(N, self.H[\"val_loss\"], label=\"val_loss\")\r\n",
        "\t\t\tplt.plot(N, self.H[\"accuracy\"], label=\"train_acc\")\r\n",
        "\t\t\tplt.plot(N, self.H[\"val_accuracy\"], label=\"val_acc\")\r\n",
        "\t\t\tplt.title(\"Training Loss and Accuracy [Epoch {}]\".format(\r\n",
        "\t\t\t\tlen(self.H[\"loss\"])))\r\n",
        "\t\t\tplt.xlabel(\"Epoch #\")\r\n",
        "\t\t\tplt.ylabel(\"Loss/Accuracy\")\r\n",
        "\t\t\tplt.legend()\r\n",
        "\r\n",
        "\t\t\t# save the figure\r\n",
        "\t\t\tplt.savefig(self.figPath)\r\n",
        "\t\t\tplt.close()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi-Xbex54MGU"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "import numpy as np\r\n",
        "import h5py\r\n",
        "\r\n",
        "class HDF5DatasetGenerator:\r\n",
        "\tdef __init__(self, dbPath, batchSize, preprocessors=None,\r\n",
        "\t\taug=None, binarize=True, classes=2):\r\n",
        "\t\t# store the batch size, preprocessors, and data augmentor,\r\n",
        "\t\t# whether or not the labels should be binarized, along with\r\n",
        "\t\t# the total number of classes\r\n",
        "\t\tself.batchSize = batchSize\r\n",
        "\t\tself.preprocessors = preprocessors\r\n",
        "\t\tself.aug = aug\r\n",
        "\t\tself.binarize = binarize\r\n",
        "\t\tself.classes = classes\r\n",
        "\r\n",
        "\t\t# open the HDF5 database for reading and determine the total\r\n",
        "\t\t# number of entries in the database\r\n",
        "\t\tself.db = h5py.File(dbPath, \"r\")\r\n",
        "\t\tself.numImages = self.db[\"labels\"].shape[0]\r\n",
        "\r\n",
        "\tdef generator(self, passes=np.inf):\r\n",
        "\t\t# initialize the epoch count\r\n",
        "\t\tepochs = 0\r\n",
        "\r\n",
        "\t\t# keep looping infinitely -- the model will stop once we have\r\n",
        "\t\t# reach the desired number of epochs\r\n",
        "\t\twhile epochs < passes:\r\n",
        "\t\t\t# loop over the HDF5 dataset\r\n",
        "\t\t\tfor i in np.arange(0, self.numImages, self.batchSize):\r\n",
        "\t\t\t\t# extract the images and labels from the HDF dataset\r\n",
        "\t\t\t\timages = self.db[\"images\"][i: i + self.batchSize]\r\n",
        "\t\t\t\tlabels = self.db[\"labels\"][i: i + self.batchSize]\r\n",
        "\r\n",
        "\t\t\t\t# check to see if the labels should be binarized\r\n",
        "\t\t\t\tif self.binarize:\r\n",
        "\t\t\t\t\tlabels = to_categorical(labels,\r\n",
        "\t\t\t\t\t\tself.classes)\r\n",
        "\r\n",
        "\t\t\t\t# check to see if our preprocessors are not None\r\n",
        "\t\t\t\tif self.preprocessors is not None:\r\n",
        "\t\t\t\t\t# initialize the list of processed images\r\n",
        "\t\t\t\t\tprocImages = []\r\n",
        "\r\n",
        "\t\t\t\t\t# loop over the images\r\n",
        "\t\t\t\t\tfor image in images:\r\n",
        "\t\t\t\t\t\t# loop over the preprocessors and apply each\r\n",
        "\t\t\t\t\t\t# to the image\r\n",
        "\t\t\t\t\t\tfor p in self.preprocessors:\r\n",
        "\t\t\t\t\t\t\timage = p.preprocess(image)\r\n",
        "\r\n",
        "\t\t\t\t\t\t# update the list of processed images\r\n",
        "\t\t\t\t\t\tprocImages.append(image)\r\n",
        "\r\n",
        "\t\t\t\t\t# update the images array to be the processed\r\n",
        "\t\t\t\t\t# images\r\n",
        "\t\t\t\t\timages = np.array(procImages)\r\n",
        "\r\n",
        "\t\t\t\t# if the data augmenator exists, apply it\r\n",
        "\t\t\t\tif self.aug is not None:\r\n",
        "\t\t\t\t\t(images, labels) = next(self.aug.flow(images,\r\n",
        "\t\t\t\t\t\tlabels, batch_size=self.batchSize))\r\n",
        "\r\n",
        "\t\t\t\t# yield a tuple of images and labels\r\n",
        "\t\t\t\tyield (images, labels)\r\n",
        "\r\n",
        "\t\t\t# increment the total number of epochs\r\n",
        "\t\t\tepochs += 1\r\n",
        "\r\n",
        "\tdef close(self):\r\n",
        "\t\t# close the database\r\n",
        "\t\tself.db.close()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFKxCuIa4Wp2"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.layers import Conv2D\r\n",
        "from tensorflow.keras.layers import AveragePooling2D\r\n",
        "from tensorflow.keras.layers import MaxPooling2D\r\n",
        "from tensorflow.keras.layers import Activation\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import concatenate\r\n",
        "from tensorflow.keras.regularizers import l2\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "class DeeperGoogLeNet:\r\n",
        "\t@staticmethod\r\n",
        "\tdef conv_module(x, K, kX, kY, stride, chanDim,padding=\"same\", reg=0.0005, name=None):\r\n",
        "\t\t# initialize the CONV, BN, and RELU layer names\r\n",
        "\t\t(convName, bnName, actName) = (None, None, None)\r\n",
        "\r\n",
        "\t\t# if a layer name was supplied, prepend it\r\n",
        "\t\tif name is not None:\r\n",
        "\t\t\tconvName = name + \"_conv\"\r\n",
        "\t\t\tbnName = name + \"_bn\"\r\n",
        "\t\t\tactName = name + \"_act\"\r\n",
        "\r\n",
        "\t\t# define a CONV => BN => RELU pattern\r\n",
        "\t\tx = Conv2D(K, (kX, kY), strides=stride, padding=padding,kernel_regularizer=l2(reg), name=convName)(x)\r\n",
        "\t\tx = BatchNormalization(axis=chanDim, name=bnName)(x)\r\n",
        "\t\tx = Activation(\"relu\", name=actName)(x)\r\n",
        "\r\n",
        "\t\t# return the block\r\n",
        "\t\treturn x\r\n",
        "\r\n",
        "\t@staticmethod\r\n",
        "\tdef inception_module(x, num1x1, num3x3Reduce, num3x3,\r\n",
        "\t\tnum5x5Reduce, num5x5, num1x1Proj, chanDim, stage,\r\n",
        "\t\treg=0.0005):\r\n",
        "\t\t# define the first branch of the Inception module which\r\n",
        "\t\t# consists of 1x1 convolutions\r\n",
        "\t\tfirst = DeeperGoogLeNet.conv_module(x, num1x1, 1, 1,(1, 1), chanDim, reg=reg, name=stage + \"_first\")\r\n",
        "\r\n",
        "\t\t# define the second branch of the Inception module which\r\n",
        "\t\t# consists of 1x1 and 3x3 convolutions\r\n",
        "\t\tsecond = DeeperGoogLeNet.conv_module(x, num3x3Reduce, 1, 1,\t(1, 1), chanDim, reg=reg, name=stage + \"_second1\")\r\n",
        "\t\tsecond = DeeperGoogLeNet.conv_module(second, num3x3, 3, 3,(1, 1), chanDim, reg=reg, name=stage + \"_second2\")\r\n",
        "\r\n",
        "\t\t# define the third branch of the Inception module which\r\n",
        "\t\t# are our 1x1 and 5x5 convolutions\r\n",
        "\t\tthird = DeeperGoogLeNet.conv_module(x, num5x5Reduce, 1, 1,(1, 1), chanDim, reg=reg, name=stage + \"_third1\")\r\n",
        "\t\tthird = DeeperGoogLeNet.conv_module(third, num5x5, 5, 5,(1, 1), chanDim, reg=reg, name=stage + \"_third2\")\r\n",
        "\r\n",
        "\t\t# define the fourth branch of the Inception module which\r\n",
        "\t\t# is the POOL projection\r\n",
        "\t\tfourth = MaxPooling2D((3, 3), strides=(1, 1),padding=\"same\", name=stage + \"_pool\")(x)\r\n",
        "\t\tfourth = DeeperGoogLeNet.conv_module(fourth, num1x1Proj,1, 1, (1, 1), chanDim, reg=reg, name=stage + \"_fourth\")\r\n",
        "\r\n",
        "\t\t# concatenate across the channel dimension\r\n",
        "\t\tx = concatenate([first, second, third, fourth], axis=chanDim,name=stage + \"_mixed\")\r\n",
        "\r\n",
        "\t\t# return the block\r\n",
        "\t\treturn x\r\n",
        "\r\n",
        "\t@staticmethod\r\n",
        "\tdef build(width, height, depth, classes, reg=0.0005):\r\n",
        "\t\t# initialize the input shape to be \"channels last\" and the\r\n",
        "\t\t# channels dimension itself\r\n",
        "\t\tinputShape = (height, width, depth)\r\n",
        "\t\tchanDim = -1\r\n",
        "\r\n",
        "\t\t# if we are using \"channels first\", update the input shape\r\n",
        "\t\t# and channels dimension\r\n",
        "\t\tif K.image_data_format() == \"channels_first\":\r\n",
        "\t\t\tinputShape = (depth, height, width)\r\n",
        "\t\t\tchanDim = 1\r\n",
        "\r\n",
        "\t\t# define the model input, followed by a sequence of CONV =>\r\n",
        "\t\t# POOL => (CONV * 2) => POOL layers\r\n",
        "\t\tinputs = Input(shape=inputShape)\r\n",
        "\t\tx = DeeperGoogLeNet.conv_module(inputs, 64, 5, 5, (1, 1),chanDim, reg=reg, name=\"block1\")\r\n",
        "\t\tx = MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\",name=\"pool1\")(x)\r\n",
        "\t\tx = DeeperGoogLeNet.conv_module(x, 64, 1, 1, (1, 1),chanDim, reg=reg, name=\"block2\")\r\n",
        "\t\tx = DeeperGoogLeNet.conv_module(x, 192, 3, 3, (1, 1),chanDim, reg=reg, name=\"block3\")\r\n",
        "\t\tx = MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\",name=\"pool2\")(x)\r\n",
        "\r\n",
        "\t\t# apply two Inception modules followed by a POOL\r\n",
        "\t\tx = DeeperGoogLeNet.inception_module(x, 64, 96, 128, 16,32, 32, chanDim, \"3a\", reg=reg)\r\n",
        "\t\tx = DeeperGoogLeNet.inception_module(x, 128, 128, 192, 32,96, 64, chanDim, \"3b\", reg=reg)\r\n",
        "\t\tx = MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\",name=\"pool3\")(x)\r\n",
        "\r\n",
        "\t\t# apply five Inception modules followed by POOL\r\n",
        "\t\tx = DeeperGoogLeNet.inception_module(x, 192, 96, 208, 16,48, 64, chanDim, \"4a\", reg=reg)\r\n",
        "\t\tx = DeeperGoogLeNet.inception_module(x, 160, 112, 224, 24,64, 64, chanDim, \"4b\", reg=reg)\r\n",
        "\t\tx = DeeperGoogLeNet.inception_module(x, 128, 128, 256, 24,64, 64, chanDim, \"4c\", reg=reg)\r\n",
        "\t\tx = DeeperGoogLeNet.inception_module(x, 112, 144, 288, 32,64, 64, chanDim, \"4d\", reg=reg)\r\n",
        "\t\tx = DeeperGoogLeNet.inception_module(x, 256, 160, 320, 32,128, 128, chanDim, \"4e\", reg=reg)\r\n",
        "\t\tx = MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\",name=\"pool4\")(x)\r\n",
        "\r\n",
        "\t\t# apply a POOL layer (average) followed by dropout\r\n",
        "\t\tx = AveragePooling2D((4, 4), name=\"pool5\")(x)\r\n",
        "\t\tx = Dropout(0.4, name=\"do\")(x)\r\n",
        "\r\n",
        "\t\t# softmax classifier\r\n",
        "\t\tx = Flatten(name=\"flatten\")(x)\r\n",
        "\t\tx = Dense(classes, kernel_regularizer=l2(reg),name=\"labels\")(x)\r\n",
        "\t\tx = Activation(\"softmax\", name=\"softmax\")(x)\r\n",
        "\r\n",
        "\t\t# create the model\r\n",
        "\t\tmodel = Model(inputs, x, name=\"googlenet\")\r\n",
        "\r\n",
        "\t\t# return the constructed network architecture\r\n",
        "\t\treturn model"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Antvve4ca1"
      },
      "source": [
        "import matplotlib\r\n",
        "matplotlib.use(\"Agg\")\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "import tensorflow.keras.backend as K\r\n",
        "import argparse\r\n",
        "import json"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYoaFYIc5UzX"
      },
      "source": [
        "# construct the training image generator for data augmentation\r\n",
        "aug = ImageDataGenerator(rotation_range=18, zoom_range=0.15,\r\n",
        "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\r\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO75ldlE5W6G"
      },
      "source": [
        "# load the RGB means for the training set\r\n",
        "means = json.loads(open(DATASET_MEAN).read())"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYabx6xH5aAD"
      },
      "source": [
        "# initialize the image preprocessors\r\n",
        "sp = SimplePreprocessor(64, 64)\r\n",
        "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\r\n",
        "iap = ImageToArrayPreprocessor()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kCSffnh5d7m"
      },
      "source": [
        "# initialize the training and validation dataset generators\r\n",
        "trainGen = HDF5DatasetGenerator(TRAIN_HDF5, 64, aug=aug,preprocessors=[sp, mp, iap], classes=NUM_CLASSES)\r\n",
        "valGen = HDF5DatasetGenerator(VAL_HDF5, 64,preprocessors=[sp, mp, iap], classes=NUM_CLASSES)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWn1nmmdC7s_"
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQyoGJtm5iKS",
        "outputId": "ebd59ee5-16ae-4936-a640-fb265dcd4a3d"
      },
      "source": [
        "# if there is no specific model checkpoint supplied, then initialize\r\n",
        "# the network and compile the model\r\n",
        "# NOTE ******************* Initial runs uncomment this *********************************\r\n",
        "#print(\"[INFO] compiling model...\")\r\n",
        "#model = DeeperGoogLeNet.build(width=64, height=64, depth=3,\tclasses=NUM_CLASSES, reg=0.0002)\r\n",
        "#opt = SGD(1e-2)\r\n",
        "#model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "# NOTE ******************* Initial runs comment this *********************************\r\n",
        "\r\n",
        "print(\"[INFO] loading {}...\".format(\"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/epoch_10.hdf5\"))\r\n",
        "model = load_model(\"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/epoch_10.hdf5\")\r\n",
        "# update the learning rate\r\n",
        "print(\"[INFO] old learning rate: {}\".format(K.get_value(model.optimizer.lr)))\r\n",
        "K.set_value(model.optimizer.lr, 1e-4)\r\n",
        "print(\"[INFO] new learning rate: {}\".format(K.get_value(model.optimizer.lr)))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading /content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/epoch_10.hdf5...\n",
            "[INFO] old learning rate: 0.0010000000474974513\n",
            "[INFO] new learning rate: 9.999999747378752e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOXqw5Uw5sAW"
      },
      "source": [
        "# construct the set of callbacks\r\n",
        "callbacks = [EpochCheckpoint(\"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5\", every=5,startAt=0),TrainingMonitor(FIG_PATH, jsonPath=JSON_PATH,\tstartAt=0)]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq_46XRG5uaJ",
        "outputId": "f6f86553-e315-4780-9c83-a7db12d57ccc"
      },
      "source": [
        "# train the network\r\n",
        "model.fit_generator(\r\n",
        "\ttrainGen.generator(),\r\n",
        "\tsteps_per_epoch=trainGen.numImages // 64,\r\n",
        "\tvalidation_data=valGen.generator(),\r\n",
        "\tvalidation_steps=valGen.numImages // 64,\r\n",
        "\tepochs=10,\r\n",
        "\tmax_queue_size=10,\r\n",
        "\tcallbacks=callbacks, verbose=1)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1406/1406 [==============================] - 232s 163ms/step - loss: 2.9914 - accuracy: 0.4857 - val_loss: 3.9127 - val_accuracy: 0.3484\n",
            "Epoch 2/10\n",
            "1406/1406 [==============================] - 274s 195ms/step - loss: 2.9844 - accuracy: 0.4887 - val_loss: 3.9042 - val_accuracy: 0.3493\n",
            "Epoch 3/10\n",
            "1406/1406 [==============================] - 275s 195ms/step - loss: 2.9807 - accuracy: 0.4899 - val_loss: 3.9104 - val_accuracy: 0.3487\n",
            "Epoch 4/10\n",
            "1406/1406 [==============================] - 275s 195ms/step - loss: 2.9810 - accuracy: 0.4883 - val_loss: 3.9075 - val_accuracy: 0.3496\n",
            "Epoch 5/10\n",
            "1406/1406 [==============================] - 274s 195ms/step - loss: 2.9781 - accuracy: 0.4911 - val_loss: 3.9123 - val_accuracy: 0.3489\n",
            "Epoch 6/10\n",
            "1406/1406 [==============================] - 274s 195ms/step - loss: 2.9723 - accuracy: 0.4898 - val_loss: 3.9177 - val_accuracy: 0.3480\n",
            "Epoch 7/10\n",
            "1406/1406 [==============================] - 274s 195ms/step - loss: 2.9762 - accuracy: 0.4896 - val_loss: 3.9161 - val_accuracy: 0.3481\n",
            "Epoch 8/10\n",
            "1406/1406 [==============================] - 274s 195ms/step - loss: 2.9761 - accuracy: 0.4913 - val_loss: 3.9014 - val_accuracy: 0.3507\n",
            "Epoch 9/10\n",
            "1406/1406 [==============================] - 274s 195ms/step - loss: 2.9735 - accuracy: 0.4910 - val_loss: 3.9182 - val_accuracy: 0.3479\n",
            "Epoch 10/10\n",
            "1406/1406 [==============================] - 274s 195ms/step - loss: 2.9720 - accuracy: 0.4901 - val_loss: 3.9067 - val_accuracy: 0.3493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcb2c50d9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlrwIX9m5xPj"
      },
      "source": [
        "#close the databases\r\n",
        "trainGen.close()\r\n",
        "valGen.close()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plR488IBcGVp"
      },
      "source": [
        ""
      ]
    }
  ]
}
