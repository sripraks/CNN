{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_tinyImageNet-200.ipynb",
      "provenance": [],
      "mount_file_id": "1M4Fts_eyfQ6QokjQ36vSYVV-4F-ngqFR",
      "authorship_tag": "ABX9TyMiH7QM0tWkMGHdkU2ktfKC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sripraks/CNN/blob/main/tinyImageNet-200/Test_GoogleNet_tinyImageNet_200.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsG5qDzJK4EQ"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "import json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A125Z3wkLM3h"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from os import path\r\n",
        "\r\n",
        "# define the paths to the training and validation directories\r\n",
        "TRAIN_IMAGES = \"/content/drive/MyDrive/dataset/tiny-imagenet-200\"\r\n",
        "VAL_IMAGES = \"/content/drive/MyDrive/dataset/tiny-imagenet-200/val\"\r\n",
        "\r\n",
        "# define the path to the file that maps validation filenames to\r\n",
        "# their corresponding class labels\r\n",
        "VAL_MAPPINGS = \"/content/drive/MyDrive/dataset/tiny-imagenet-200/val/val_annotations.txt\"\r\n",
        "\r\n",
        "# define the paths to the WordNet hierarchy files which are used\r\n",
        "# to generate our class labels\r\n",
        "WORDNET_IDS = \"/content/drive/MyDrive/dataset/tiny-imagenet-200/wnids.txt\"\r\n",
        "WORD_LABELS = \"/content/drive/MyDrive/dataset/tiny-imagenet-200/words.txt\"\r\n",
        "\r\n",
        "# since we do not have access to the testing data we need to\r\n",
        "# take a number of images from the training data and use it instead\r\n",
        "NUM_CLASSES = 200\r\n",
        "NUM_TEST_IMAGES = 50 * NUM_CLASSES\r\n",
        "\r\n",
        "# define the path to the output training, validation, and testing\r\n",
        "# HDF5 files\r\n",
        "TRAIN_HDF5 = \"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/train.hdf5\"\r\n",
        "VAL_HDF5 = \"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/val.hdf5\"\r\n",
        "TEST_HDF5 = \"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/test.hdf5\"\r\n",
        "\r\n",
        "# define the path to the dataset mean\r\n",
        "DATASET_MEAN = \"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/output/tiny-image-net-200-mean.json\"\r\n",
        "\r\n",
        "# define the path to the output directory used for storing plots,\r\n",
        "# classification reports, etc.\r\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/output\"\r\n",
        "MODEL_PATH = path.sep.join([OUTPUT_PATH,\"checkpoints\", \"epoch_70.hdf5\"])\r\n",
        "FIG_PATH = path.sep.join([OUTPUT_PATH,\"deepergooglenet_tinyimagenet.png\"])\r\n",
        "JSON_PATH = path.sep.join([OUTPUT_PATH,\"deepergooglenet_tinyimagenet.json\"])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IArdSNuTLQwS"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\r\n",
        "\r\n",
        "class ImageToArrayPreprocessor:\r\n",
        "\tdef __init__(self, dataFormat=None):\r\n",
        "\t\t# store the image data format\r\n",
        "\t\tself.dataFormat = dataFormat\r\n",
        "\r\n",
        "\tdef preprocess(self, image):\r\n",
        "\t\t# apply the Keras utility function that correctly rearranges\r\n",
        "\t\t# the dimensions of the image\r\n",
        "\t\treturn img_to_array(image, data_format=self.dataFormat)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OatFVeaaLTt1"
      },
      "source": [
        "# import the necessary packages\r\n",
        "import cv2\r\n",
        "\r\n",
        "class SimplePreprocessor:\r\n",
        "\tdef __init__(self, width, height, inter=cv2.INTER_AREA):\r\n",
        "\t\t# store the target image width, height, and interpolation\r\n",
        "\t\t# method used when resizing\r\n",
        "\t\tself.width = width\r\n",
        "\t\tself.height = height\r\n",
        "\t\tself.inter = inter\r\n",
        "\r\n",
        "\tdef preprocess(self, image):\r\n",
        "\t\t# resize the image to a fixed size, ignoring the aspect\r\n",
        "\t\t# ratio\r\n",
        "\t\treturn cv2.resize(image, (self.width, self.height),interpolation=self.inter)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl8Sb394LVyw"
      },
      "source": [
        "# import the necessary packages\r\n",
        "import cv2\r\n",
        "\r\n",
        "class MeanPreprocessor:\r\n",
        "\tdef __init__(self, rMean, gMean, bMean):\r\n",
        "\t\t# store the Red, Green, and Blue channel averages across a\r\n",
        "\t\t# training set\r\n",
        "\t\tself.rMean = rMean\r\n",
        "\t\tself.gMean = gMean\r\n",
        "\t\tself.bMean = bMean\r\n",
        "\r\n",
        "\tdef preprocess(self, image):\r\n",
        "\t\t# split the image into its respective Red, Green, and Blue\r\n",
        "\t\t# channels\r\n",
        "\t\t(B, G, R) = cv2.split(image.astype(\"float32\"))\r\n",
        "\r\n",
        "\t\t# subtract the means for each channel\r\n",
        "\t\tR -= self.rMean\r\n",
        "\t\tG -= self.gMean\r\n",
        "\t\tB -= self.bMean\r\n",
        "\r\n",
        "\t\t# merge the channels back together and return the image\r\n",
        "\t\treturn cv2.merge([B, G, R])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPIRz6wMLc8C"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "import numpy as np\r\n",
        "import h5py\r\n",
        "\r\n",
        "class HDF5DatasetGenerator:\r\n",
        "\tdef __init__(self, dbPath, batchSize, preprocessors=None,\r\n",
        "\t\taug=None, binarize=True, classes=2):\r\n",
        "\t\t# store the batch size, preprocessors, and data augmentor,\r\n",
        "\t\t# whether or not the labels should be binarized, along with\r\n",
        "\t\t# the total number of classes\r\n",
        "\t\tself.batchSize = batchSize\r\n",
        "\t\tself.preprocessors = preprocessors\r\n",
        "\t\tself.aug = aug\r\n",
        "\t\tself.binarize = binarize\r\n",
        "\t\tself.classes = classes\r\n",
        "\r\n",
        "\t\t# open the HDF5 database for reading and determine the total\r\n",
        "\t\t# number of entries in the database\r\n",
        "\t\tself.db = h5py.File(dbPath, \"r\")\r\n",
        "\t\tself.numImages = self.db[\"labels\"].shape[0]\r\n",
        "\r\n",
        "\tdef generator(self, passes=np.inf):\r\n",
        "\t\t# initialize the epoch count\r\n",
        "\t\tepochs = 0\r\n",
        "\r\n",
        "\t\t# keep looping infinitely -- the model will stop once we have\r\n",
        "\t\t# reach the desired number of epochs\r\n",
        "\t\twhile epochs < passes:\r\n",
        "\t\t\t# loop over the HDF5 dataset\r\n",
        "\t\t\tfor i in np.arange(0, self.numImages, self.batchSize):\r\n",
        "\t\t\t\t# extract the images and labels from the HDF dataset\r\n",
        "\t\t\t\timages = self.db[\"images\"][i: i + self.batchSize]\r\n",
        "\t\t\t\tlabels = self.db[\"labels\"][i: i + self.batchSize]\r\n",
        "\r\n",
        "\t\t\t\t# check to see if the labels should be binarized\r\n",
        "\t\t\t\tif self.binarize:\r\n",
        "\t\t\t\t\tlabels = to_categorical(labels,\r\n",
        "\t\t\t\t\t\tself.classes)\r\n",
        "\r\n",
        "\t\t\t\t# check to see if our preprocessors are not None\r\n",
        "\t\t\t\tif self.preprocessors is not None:\r\n",
        "\t\t\t\t\t# initialize the list of processed images\r\n",
        "\t\t\t\t\tprocImages = []\r\n",
        "\r\n",
        "\t\t\t\t\t# loop over the images\r\n",
        "\t\t\t\t\tfor image in images:\r\n",
        "\t\t\t\t\t\t# loop over the preprocessors and apply each\r\n",
        "\t\t\t\t\t\t# to the image\r\n",
        "\t\t\t\t\t\tfor p in self.preprocessors:\r\n",
        "\t\t\t\t\t\t\timage = p.preprocess(image)\r\n",
        "\r\n",
        "\t\t\t\t\t\t# update the list of processed images\r\n",
        "\t\t\t\t\t\tprocImages.append(image)\r\n",
        "\r\n",
        "\t\t\t\t\t# update the images array to be the processed\r\n",
        "\t\t\t\t\t# images\r\n",
        "\t\t\t\t\timages = np.array(procImages)\r\n",
        "\r\n",
        "\t\t\t\t# if the data augmenator exists, apply it\r\n",
        "\t\t\t\tif self.aug is not None:\r\n",
        "\t\t\t\t\t(images, labels) = next(self.aug.flow(images,\r\n",
        "\t\t\t\t\t\tlabels, batch_size=self.batchSize))\r\n",
        "\r\n",
        "\t\t\t\t# yield a tuple of images and labels\r\n",
        "\t\t\t\tyield (images, labels)\r\n",
        "\r\n",
        "\t\t\t# increment the total number of epochs\r\n",
        "\t\t\tepochs += 1\r\n",
        "\r\n",
        "\tdef close(self):\r\n",
        "\t\t# close the database\r\n",
        "\t\tself.db.close()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kax5tgP5Lk4l"
      },
      "source": [
        "# import the necessary packages\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def rank5_accuracy(preds, labels):\r\n",
        "\t# initialize the rank-1 and rank-5 accuracies\r\n",
        "\trank1 = 0\r\n",
        "\trank5 = 0\r\n",
        "\r\n",
        "\t# loop over the predictions and ground-truth labels\r\n",
        "\tfor (p, gt) in zip(preds, labels):\r\n",
        "\t\t# sort the probabilities by their index in descending\r\n",
        "\t\t# order so that the more confident guesses are at the\r\n",
        "\t\t# front of the list\r\n",
        "\t\tp = np.argsort(p)[::-1]\r\n",
        "\r\n",
        "\t\t# check if the ground-truth label is in the top-5\r\n",
        "\t\t# predictions\r\n",
        "\t\tif gt in p[:5]:\r\n",
        "\t\t\trank5 += 1\r\n",
        "\r\n",
        "\t\t# check to see if the ground-truth is the #1 prediction\r\n",
        "\t\tif gt == p[0]:\r\n",
        "\t\t\trank1 += 1\r\n",
        "\r\n",
        "\t# compute the final rank-1 and rank-5 accuracies\r\n",
        "\trank1 /= float(len(preds))\r\n",
        "\trank5 /= float(len(preds))\r\n",
        "\r\n",
        "\t# return a tuple of the rank-1 and rank-5 accuracies\r\n",
        "\treturn (rank1, rank5)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRLg0TMcLtjD"
      },
      "source": [
        "# load the RGB means for the training set\r\n",
        "means = json.loads(open(DATASET_MEAN).read())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hNBdyV2LvVz"
      },
      "source": [
        "# initialize the image preprocessors\r\n",
        "sp = SimplePreprocessor(64, 64)\r\n",
        "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\r\n",
        "iap = ImageToArrayPreprocessor()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYNw1Y_lLxOQ"
      },
      "source": [
        "# initialize the testing dataset generator\r\n",
        "testGen = HDF5DatasetGenerator(\"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/test.hdf5\", 64,preprocessors=[sp, mp, iap], classes=NUM_CLASSES)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4o38yrDLzEB",
        "outputId": "d5a92b1d-9be5-4955-e5fe-2e22a0662c02"
      },
      "source": [
        "# load the pre-trained network\r\n",
        "print(\"[INFO] loading model...\")\r\n",
        "model = load_model(\"/content/drive/MyDrive/dataset/tiny-imagenet-200-hdf5/epoch_10.hdf5\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDtki7tPL1FT",
        "outputId": "8fea7a12-71a4-47c1-edf9-e7801607df6f"
      },
      "source": [
        "# make predictions on the testing data\r\n",
        "print(\"[INFO] predicting on test data...\")\r\n",
        "predictions = model.predict_generator(testGen.generator(),\tsteps=testGen.numImages // 64, max_queue_size=10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] predicting on test data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q4_wbr8L9IS",
        "outputId": "1904ad40-e02d-48ab-cc0f-e4a9e549cbdc"
      },
      "source": [
        "# compute the rank-1 and rank-5 accuracies\r\n",
        "(rank1, rank5) = rank5_accuracy(predictions, testGen.db[\"labels\"])\r\n",
        "print(\"[INFO] rank-1: {:.2f}%\".format(rank1 * 100))\r\n",
        "print(\"[INFO] rank-5: {:.2f}%\".format(rank5 * 100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] rank-1: 45.91%\n",
            "[INFO] rank-5: 71.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrfwZKIpL-5X"
      },
      "source": [
        "# close the database\r\n",
        "testGen.close()"
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}