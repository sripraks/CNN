{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MiniGoogLenet.ipynb",
      "provenance": [],
      "mount_file_id": "1dj1wgNF633EZXGEGZS6bXMTVHwZJJZJp",
      "authorship_tag": "ABX9TyN1KdVEz/wyJIv3Sf1WZfzu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sripraks/CNN/blob/main/cifar10/MiniGoogLenet_expriment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F38O8PgreXfV"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.layers import Conv2D\r\n",
        "from tensorflow.keras.layers import AveragePooling2D\r\n",
        "from tensorflow.keras.layers import MaxPooling2D\r\n",
        "from tensorflow.keras.layers import Activation\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import concatenate\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "class MiniGoogLeNet:\r\n",
        "\t@staticmethod\r\n",
        "\tdef conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\"):\r\n",
        "\t\t# define a CONV => BN => RELU pattern\r\n",
        "\t\tx = Conv2D(K, (kX, kY), strides=stride, padding=padding)(x)\r\n",
        "\t\tx = BatchNormalization(axis=chanDim)(x)\r\n",
        "\t\tx = Activation(\"relu\")(x)\r\n",
        "\r\n",
        "\t\t# return the block\r\n",
        "\t\treturn x\r\n",
        "\r\n",
        "\t@staticmethod\r\n",
        "\tdef inception_module(x, numK1x1, numK3x3, chanDim):\r\n",
        "\t\t# define two CONV modules, then concatenate across the\r\n",
        "\t\t# channel dimension\r\n",
        "\t\tconv_1x1 = MiniGoogLeNet.conv_module(x, numK1x1, 1, 1,\r\n",
        "\t\t\t(1, 1), chanDim)\r\n",
        "\t\tconv_3x3 = MiniGoogLeNet.conv_module(x, numK3x3, 3, 3,\r\n",
        "\t\t\t(1, 1), chanDim)\r\n",
        "\t\tx = concatenate([conv_1x1, conv_3x3], axis=chanDim)\r\n",
        "\r\n",
        "\t\t# return the block\r\n",
        "\t\treturn x\r\n",
        "\r\n",
        "\t@staticmethod\r\n",
        "\tdef downsample_module(x, K, chanDim):\r\n",
        "\t\t# define the CONV module and POOL, then concatenate\r\n",
        "\t\t# across the channel dimensions\r\n",
        "\t\tconv_3x3 = MiniGoogLeNet.conv_module(x, K, 3, 3, (2, 2),\r\n",
        "\t\t\tchanDim, padding=\"valid\")\r\n",
        "\t\tpool = MaxPooling2D((3, 3), strides=(2, 2))(x)\r\n",
        "\t\tx = concatenate([conv_3x3, pool], axis=chanDim)\r\n",
        "\r\n",
        "\t\t# return the block\r\n",
        "\t\treturn x\r\n",
        "\r\n",
        "\t@staticmethod\r\n",
        "\tdef build(width, height, depth, classes):\r\n",
        "\t\t# initialize the input shape to be \"channels last\" and the\r\n",
        "\t\t# channels dimension itself\r\n",
        "\t\tinputShape = (height, width, depth)\r\n",
        "\t\tchanDim = -1\r\n",
        "\r\n",
        "\t\t# if we are using \"channels first\", update the input shape\r\n",
        "\t\t# and channels dimension\r\n",
        "\t\tif K.image_data_format() == \"channels_first\":\r\n",
        "\t\t\tinputShape = (depth, height, width)\r\n",
        "\t\t\tchanDim = 1\r\n",
        "\r\n",
        "\t\t# define the model input and first CONV module\r\n",
        "\t\tinputs = Input(shape=inputShape)\r\n",
        "\t\tx = MiniGoogLeNet.conv_module(inputs, 96, 3, 3, (1, 1),\r\n",
        "\t\t\tchanDim)\r\n",
        "\r\n",
        "\t\t# two Inception modules followed by a downsample module\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 32, 32, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 32, 48, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.downsample_module(x, 80, chanDim)\r\n",
        "\r\n",
        "\t\t# four Inception modules followed by a downsample module\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 112, 48, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 96, 64, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 80, 80, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 48, 96, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.downsample_module(x, 96, chanDim)\r\n",
        "\r\n",
        "\t\t# two Inception modules followed by global POOL and dropout\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 176, 160, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 176, 160, chanDim)\r\n",
        "\t\tx = AveragePooling2D((7, 7))(x)\r\n",
        "\t\tx = Dropout(0.5)(x)\r\n",
        "\r\n",
        "\t\t# softmax classifier\r\n",
        "\t\tx = Flatten()(x)\r\n",
        "\t\tx = Dense(classes)(x)\r\n",
        "\t\tx = Activation(\"softmax\")(x)\r\n",
        "\r\n",
        "\t\t# create the model\r\n",
        "\t\tmodel = Model(inputs, x, name=\"googlenet\")\r\n",
        "\r\n",
        "\t\t# return the constructed network architecture\r\n",
        "\t\treturn model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gVua4L6e5ym"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.callbacks import BaseLogger\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import os\r\n",
        "\r\n",
        "class TrainingMonitor(BaseLogger):\r\n",
        "\tdef __init__(self, figPath, jsonPath=None, startAt=0):\r\n",
        "\t\t# store the output path for the figure, the path to the JSON\r\n",
        "\t\t# serialized file, and the starting epoch\r\n",
        "\t\tsuper(TrainingMonitor, self).__init__()\r\n",
        "\t\tself.figPath = figPath\r\n",
        "\t\tself.jsonPath = jsonPath\r\n",
        "\t\tself.startAt = startAt\r\n",
        "\r\n",
        "\tdef on_train_begin(self, logs={}):\r\n",
        "\t\t# initialize the history dictionary\r\n",
        "\t\tself.H = {}\r\n",
        "\r\n",
        "\t\t# if the JSON history path exists, load the training history\r\n",
        "\t\tif self.jsonPath is not None:\r\n",
        "\t\t\tif os.path.exists(self.jsonPath):\r\n",
        "\t\t\t\tself.H = json.loads(open(self.jsonPath).read())\r\n",
        "\r\n",
        "\t\t\t\t# check to see if a starting epoch was supplied\r\n",
        "\t\t\t\tif self.startAt > 0:\r\n",
        "\t\t\t\t\t# loop over the entries in the history log and\r\n",
        "\t\t\t\t\t# trim any entries that are past the starting\r\n",
        "\t\t\t\t\t# epoch\r\n",
        "\t\t\t\t\tfor k in self.H.keys():\r\n",
        "\t\t\t\t\t\tself.H[k] = self.H[k][:self.startAt]\r\n",
        "\r\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\r\n",
        "\t\t# loop over the logs and update the loss, accuracy, etc.\r\n",
        "\t\t# for the entire training process\r\n",
        "\t\tfor (k, v) in logs.items():\r\n",
        "\t\t\tl = self.H.get(k, [])\r\n",
        "\t\t\tl.append(float(v))\r\n",
        "\t\t\tself.H[k] = l\r\n",
        "\r\n",
        "\t\t# check to see if the training history should be serialized\r\n",
        "\t\t# to file\r\n",
        "\t\tif self.jsonPath is not None:\r\n",
        "\t\t\tf = open(self.jsonPath, \"w\")\r\n",
        "\t\t\tf.write(json.dumps(self.H))\r\n",
        "\t\t\tf.close()\r\n",
        "\r\n",
        "\t\t# ensure at least two epochs have passed before plotting\r\n",
        "\t\t# (epoch starts at zero)\r\n",
        "\t\tif len(self.H[\"loss\"]) > 1:\r\n",
        "\t\t\t# plot the training loss and accuracy\r\n",
        "\t\t\tN = np.arange(0, len(self.H[\"loss\"]))\r\n",
        "\t\t\tplt.style.use(\"ggplot\")\r\n",
        "\t\t\tplt.figure()\r\n",
        "\t\t\tplt.plot(N, self.H[\"loss\"], label=\"train_loss\")\r\n",
        "\t\t\tplt.plot(N, self.H[\"val_loss\"], label=\"val_loss\")\r\n",
        "\t\t\tplt.plot(N, self.H[\"accuracy\"], label=\"train_acc\")\r\n",
        "\t\t\tplt.plot(N, self.H[\"val_accuracy\"], label=\"val_acc\")\r\n",
        "\t\t\tplt.title(\"Training Loss and Accuracy [Epoch {}]\".format(\r\n",
        "\t\t\t\tlen(self.H[\"loss\"])))\r\n",
        "\t\t\tplt.xlabel(\"Epoch #\")\r\n",
        "\t\t\tplt.ylabel(\"Loss/Accuracy\")\r\n",
        "\t\t\tplt.legend()\r\n",
        "\r\n",
        "\t\t\t# save the figure\r\n",
        "\t\t\tplt.savefig(self.figPath)\r\n",
        "\t\t\tplt.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpcGw3FEeuso"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\r\n",
        "from tensorflow.keras.optimizers import SGD\r\n",
        "from tensorflow.keras.datasets import cifar10\r\n",
        "import numpy as np\r\n",
        "import argparse\r\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbsqWySaeoaG"
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\r\n",
        "import matplotlib\r\n",
        "matplotlib.use(\"Agg\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNycW6lceruW"
      },
      "source": [
        "# definine the total number of epochs to train for along with the\r\n",
        "# initial learning rate\r\n",
        "NUM_EPOCHS = 70\r\n",
        "INIT_LR = 1e-3"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elmgLY8UesaG"
      },
      "source": [
        "def poly_decay(epoch):\r\n",
        "\t# initialize the maximum number of epochs, base learning rate,\r\n",
        "\t# and power of the polynomial\r\n",
        "\tmaxEpochs = NUM_EPOCHS\r\n",
        "\tbaseLR = INIT_LR\r\n",
        "\tpower = 1.0\r\n",
        "\r\n",
        "\t# compute the new learning rate based on polynomial decay\r\n",
        "\talpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\r\n",
        "\r\n",
        "\t# return the new learning rate\r\n",
        "\treturn alpha"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBvUUGjEfCfq",
        "outputId": "2e5940b3-b869-4191-fab7-7b7693c52aa5"
      },
      "source": [
        "# load the training and testing data, converting the images from\r\n",
        "# integers to floats\r\n",
        "print(\"[INFO] loading CIFAR-10 data...\")\r\n",
        "((trainX, trainY), (testX, testY)) = cifar10.load_data()\r\n",
        "trainX = trainX.astype(\"float\")\r\n",
        "testX = testX.astype(\"float\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading CIFAR-10 data...\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28yfuniHfLi7"
      },
      "source": [
        "# apply mean subtraction to the data\r\n",
        "mean = np.mean(trainX, axis=0)\r\n",
        "trainX -= mean\r\n",
        "testX -= mean"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUnpOoz_fNno"
      },
      "source": [
        "# convert the labels from integers to vectors\r\n",
        "lb = LabelBinarizer()\r\n",
        "trainY = lb.fit_transform(trainY)\r\n",
        "testY = lb.transform(testY)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8MPnl6bfP2p"
      },
      "source": [
        "# construct the image generator for data augmentation\r\n",
        "aug = ImageDataGenerator(width_shift_range=0.1,\r\n",
        "\theight_shift_range=0.1, horizontal_flip=True,\r\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhSOD7XofYs3"
      },
      "source": [
        "# construct the set of callbacks\r\n",
        "figPath = os.path.sep.join([\"/content/sample_data/output\", \"{}.png\".format(os.getpid())])\r\n",
        "jsonPath = os.path.sep.join([\"/content/sample_data/output\", \"{}.json\".format(os.getpid())])\r\n",
        "\r\n",
        "callbacks = [TrainingMonitor(figPath, jsonPath=jsonPath),LearningRateScheduler(poly_decay)]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfpsKDfbfarX",
        "outputId": "cc5aaec2-3fd7-407d-bb0f-7b103f7a43be"
      },
      "source": [
        "# initialize the optimizer and model\r\n",
        "print(\"[INFO] compiling model...\")\r\n",
        "opt = SGD(lr=INIT_LR, momentum=0.9)\r\n",
        "model = MiniGoogLeNet.build(width=32, height=32, depth=3, classes=10)\r\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\tmetrics=[\"accuracy\"])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy6Jg6psfdU5",
        "outputId": "0265641f-f2e5-4278-af92-22cfa069cc03"
      },
      "source": [
        "# train the network\r\n",
        "print(\"[INFO] training network...\")\r\n",
        "model.fit_generator(aug.flow(trainX, trainY, batch_size=64),validation_data=(testX, testY), steps_per_epoch=len(trainX) // 64,epochs=NUM_EPOCHS, callbacks=callbacks, verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n",
            "WARNING:tensorflow:From <ipython-input-16-35c7be4d18f6>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/70\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 1.6941 - accuracy: 0.3709 - val_loss: 1.3804 - val_accuracy: 0.5087\n",
            "Epoch 2/70\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 1.3388 - accuracy: 0.5164 - val_loss: 1.2918 - val_accuracy: 0.5382\n",
            "Epoch 3/70\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 1.1814 - accuracy: 0.5758 - val_loss: 1.1122 - val_accuracy: 0.6077\n",
            "Epoch 4/70\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 1.0776 - accuracy: 0.6146 - val_loss: 1.2426 - val_accuracy: 0.5804\n",
            "Epoch 5/70\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.9932 - accuracy: 0.6505 - val_loss: 1.1627 - val_accuracy: 0.5977\n",
            "Epoch 6/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.9250 - accuracy: 0.6749 - val_loss: 0.9619 - val_accuracy: 0.6588\n",
            "Epoch 7/70\n",
            "781/781 [==============================] - 39s 49ms/step - loss: 0.8798 - accuracy: 0.6920 - val_loss: 0.8749 - val_accuracy: 0.6903\n",
            "Epoch 8/70\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.8256 - accuracy: 0.7140 - val_loss: 0.9686 - val_accuracy: 0.6659\n",
            "Epoch 9/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.7903 - accuracy: 0.7235 - val_loss: 0.8219 - val_accuracy: 0.7105\n",
            "Epoch 10/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.7534 - accuracy: 0.7359 - val_loss: 0.7995 - val_accuracy: 0.7197\n",
            "Epoch 11/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.7224 - accuracy: 0.7499 - val_loss: 0.8319 - val_accuracy: 0.7128\n",
            "Epoch 12/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.6954 - accuracy: 0.7578 - val_loss: 0.6695 - val_accuracy: 0.7680\n",
            "Epoch 13/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.6655 - accuracy: 0.7706 - val_loss: 0.7327 - val_accuracy: 0.7493\n",
            "Epoch 14/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.6399 - accuracy: 0.7805 - val_loss: 0.7349 - val_accuracy: 0.7477\n",
            "Epoch 15/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.6217 - accuracy: 0.7884 - val_loss: 1.1568 - val_accuracy: 0.6546\n",
            "Epoch 16/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.6059 - accuracy: 0.7920 - val_loss: 0.6495 - val_accuracy: 0.7767\n",
            "Epoch 17/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5848 - accuracy: 0.7993 - val_loss: 0.7765 - val_accuracy: 0.7332\n",
            "Epoch 18/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5597 - accuracy: 0.8089 - val_loss: 0.5825 - val_accuracy: 0.8040\n",
            "Epoch 19/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5487 - accuracy: 0.8129 - val_loss: 0.5848 - val_accuracy: 0.8019\n",
            "Epoch 20/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5346 - accuracy: 0.8180 - val_loss: 0.6318 - val_accuracy: 0.7867\n",
            "Epoch 21/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5218 - accuracy: 0.8221 - val_loss: 0.5900 - val_accuracy: 0.7979\n",
            "Epoch 22/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.5014 - accuracy: 0.8308 - val_loss: 0.6626 - val_accuracy: 0.7772\n",
            "Epoch 23/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4937 - accuracy: 0.8338 - val_loss: 0.5417 - val_accuracy: 0.8147\n",
            "Epoch 24/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4792 - accuracy: 0.8356 - val_loss: 0.5676 - val_accuracy: 0.8101\n",
            "Epoch 25/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4705 - accuracy: 0.8393 - val_loss: 0.5237 - val_accuracy: 0.8214\n",
            "Epoch 26/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4635 - accuracy: 0.8428 - val_loss: 0.6865 - val_accuracy: 0.7804\n",
            "Epoch 27/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4484 - accuracy: 0.8486 - val_loss: 0.8065 - val_accuracy: 0.7423\n",
            "Epoch 28/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4414 - accuracy: 0.8505 - val_loss: 0.5123 - val_accuracy: 0.8261\n",
            "Epoch 29/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4309 - accuracy: 0.8537 - val_loss: 0.4986 - val_accuracy: 0.8320\n",
            "Epoch 30/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4209 - accuracy: 0.8559 - val_loss: 0.5091 - val_accuracy: 0.8260\n",
            "Epoch 31/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4160 - accuracy: 0.8562 - val_loss: 0.5296 - val_accuracy: 0.8215\n",
            "Epoch 32/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4034 - accuracy: 0.8628 - val_loss: 0.5286 - val_accuracy: 0.8219\n",
            "Epoch 33/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4026 - accuracy: 0.8617 - val_loss: 0.4887 - val_accuracy: 0.8341\n",
            "Epoch 34/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3911 - accuracy: 0.8672 - val_loss: 0.5232 - val_accuracy: 0.8250\n",
            "Epoch 35/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3840 - accuracy: 0.8696 - val_loss: 0.4808 - val_accuracy: 0.8342\n",
            "Epoch 36/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3788 - accuracy: 0.8724 - val_loss: 0.6131 - val_accuracy: 0.8075\n",
            "Epoch 37/70\n",
            "781/781 [==============================] - 39s 49ms/step - loss: 0.3721 - accuracy: 0.8749 - val_loss: 0.4745 - val_accuracy: 0.8450\n",
            "Epoch 38/70\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.3634 - accuracy: 0.8783 - val_loss: 0.5279 - val_accuracy: 0.8308\n",
            "Epoch 39/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.3541 - accuracy: 0.8798 - val_loss: 0.4562 - val_accuracy: 0.8459\n",
            "Epoch 40/70\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.3486 - accuracy: 0.8805 - val_loss: 0.5380 - val_accuracy: 0.8243\n",
            "Epoch 41/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.3435 - accuracy: 0.8846 - val_loss: 0.4862 - val_accuracy: 0.8367\n",
            "Epoch 42/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.3366 - accuracy: 0.8854 - val_loss: 0.4728 - val_accuracy: 0.8457\n",
            "Epoch 43/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.3301 - accuracy: 0.8866 - val_loss: 0.5179 - val_accuracy: 0.8320\n",
            "Epoch 44/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.3265 - accuracy: 0.8902 - val_loss: 0.4399 - val_accuracy: 0.8549\n",
            "Epoch 45/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.3272 - accuracy: 0.8885 - val_loss: 0.4713 - val_accuracy: 0.8425\n",
            "Epoch 46/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.3183 - accuracy: 0.8911 - val_loss: 0.5054 - val_accuracy: 0.8347\n",
            "Epoch 47/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.3092 - accuracy: 0.8952 - val_loss: 0.4937 - val_accuracy: 0.8411\n",
            "Epoch 48/70\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.3015 - accuracy: 0.8968 - val_loss: 0.5191 - val_accuracy: 0.8323\n",
            "Epoch 49/70\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.3022 - accuracy: 0.8978 - val_loss: 0.4649 - val_accuracy: 0.8522\n",
            "Epoch 50/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2945 - accuracy: 0.9001 - val_loss: 0.4676 - val_accuracy: 0.8482\n",
            "Epoch 51/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2941 - accuracy: 0.9001 - val_loss: 0.4500 - val_accuracy: 0.8512\n",
            "Epoch 52/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2842 - accuracy: 0.9045 - val_loss: 0.4744 - val_accuracy: 0.8464\n",
            "Epoch 53/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2829 - accuracy: 0.9042 - val_loss: 0.4739 - val_accuracy: 0.8436\n",
            "Epoch 54/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2813 - accuracy: 0.9041 - val_loss: 0.4349 - val_accuracy: 0.8580\n",
            "Epoch 55/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2766 - accuracy: 0.9053 - val_loss: 0.4612 - val_accuracy: 0.8491\n",
            "Epoch 56/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2752 - accuracy: 0.9065 - val_loss: 0.4324 - val_accuracy: 0.8568\n",
            "Epoch 57/70\n",
            "781/781 [==============================] - 39s 49ms/step - loss: 0.2677 - accuracy: 0.9095 - val_loss: 0.4191 - val_accuracy: 0.8593\n",
            "Epoch 58/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2650 - accuracy: 0.9103 - val_loss: 0.4544 - val_accuracy: 0.8535\n",
            "Epoch 59/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2615 - accuracy: 0.9112 - val_loss: 0.4125 - val_accuracy: 0.8623\n",
            "Epoch 60/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2569 - accuracy: 0.9147 - val_loss: 0.4191 - val_accuracy: 0.8648\n",
            "Epoch 61/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2585 - accuracy: 0.9118 - val_loss: 0.4349 - val_accuracy: 0.8584\n",
            "Epoch 62/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2541 - accuracy: 0.9150 - val_loss: 0.4265 - val_accuracy: 0.8578\n",
            "Epoch 63/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2516 - accuracy: 0.9153 - val_loss: 0.4070 - val_accuracy: 0.8654\n",
            "Epoch 64/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2444 - accuracy: 0.9169 - val_loss: 0.4083 - val_accuracy: 0.8655\n",
            "Epoch 65/70\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.2453 - accuracy: 0.9169 - val_loss: 0.4110 - val_accuracy: 0.8635\n",
            "Epoch 66/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2414 - accuracy: 0.9187 - val_loss: 0.4057 - val_accuracy: 0.8657\n",
            "Epoch 67/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2393 - accuracy: 0.9196 - val_loss: 0.4128 - val_accuracy: 0.8647\n",
            "Epoch 68/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2390 - accuracy: 0.9194 - val_loss: 0.4051 - val_accuracy: 0.8691\n",
            "Epoch 69/70\n",
            "781/781 [==============================] - 39s 49ms/step - loss: 0.2380 - accuracy: 0.9192 - val_loss: 0.4101 - val_accuracy: 0.8674\n",
            "Epoch 70/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2340 - accuracy: 0.9219 - val_loss: 0.3970 - val_accuracy: 0.8694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faba3ef6eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBR2YSKOff2m"
      },
      "source": [
        "# save the network to disk\r\n",
        "print(\"[INFO] serializing network...\")\r\n",
        "model.save(\"/content/sample_data/output/minigooglenet_cifar10.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOzmFTWUhuNt"
      },
      "source": [
        ""
      ]
    }
  ]
}