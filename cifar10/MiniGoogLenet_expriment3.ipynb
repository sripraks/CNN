{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MiniGoogLenet.ipynb",
      "provenance": [],
      "mount_file_id": "1dj1wgNF633EZXGEGZS6bXMTVHwZJJZJp",
      "authorship_tag": "ABX9TyOtbfmzoGKk/S5sEAhcStPj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sripraks/CNN/blob/main/cifar10/MiniGoogLenet_expriment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F38O8PgreXfV"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.layers import Conv2D\r\n",
        "from tensorflow.keras.layers import AveragePooling2D\r\n",
        "from tensorflow.keras.layers import MaxPooling2D\r\n",
        "from tensorflow.keras.layers import Activation\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import concatenate\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "class MiniGoogLeNet:\r\n",
        "\t@staticmethod\r\n",
        "\tdef conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\"):\r\n",
        "\t\t# define a CONV => BN => RELU pattern\r\n",
        "\t\tx = Conv2D(K, (kX, kY), strides=stride, padding=padding)(x)\r\n",
        "\t\tx = BatchNormalization(axis=chanDim)(x)\r\n",
        "\t\tx = Activation(\"relu\")(x)\r\n",
        "\r\n",
        "\t\t# return the block\r\n",
        "\t\treturn x\r\n",
        "\r\n",
        "\t@staticmethod\r\n",
        "\tdef inception_module(x, numK1x1, numK3x3, chanDim):\r\n",
        "\t\t# define two CONV modules, then concatenate across the\r\n",
        "\t\t# channel dimension\r\n",
        "\t\tconv_1x1 = MiniGoogLeNet.conv_module(x, numK1x1, 1, 1,\r\n",
        "\t\t\t(1, 1), chanDim)\r\n",
        "\t\tconv_3x3 = MiniGoogLeNet.conv_module(x, numK3x3, 3, 3,\r\n",
        "\t\t\t(1, 1), chanDim)\r\n",
        "\t\tx = concatenate([conv_1x1, conv_3x3], axis=chanDim)\r\n",
        "\r\n",
        "\t\t# return the block\r\n",
        "\t\treturn x\r\n",
        "\r\n",
        "\t@staticmethod\r\n",
        "\tdef downsample_module(x, K, chanDim):\r\n",
        "\t\t# define the CONV module and POOL, then concatenate\r\n",
        "\t\t# across the channel dimensions\r\n",
        "\t\tconv_3x3 = MiniGoogLeNet.conv_module(x, K, 3, 3, (2, 2),\r\n",
        "\t\t\tchanDim, padding=\"valid\")\r\n",
        "\t\tpool = MaxPooling2D((3, 3), strides=(2, 2))(x)\r\n",
        "\t\tx = concatenate([conv_3x3, pool], axis=chanDim)\r\n",
        "\r\n",
        "\t\t# return the block\r\n",
        "\t\treturn x\r\n",
        "\r\n",
        "\t@staticmethod\r\n",
        "\tdef build(width, height, depth, classes):\r\n",
        "\t\t# initialize the input shape to be \"channels last\" and the\r\n",
        "\t\t# channels dimension itself\r\n",
        "\t\tinputShape = (height, width, depth)\r\n",
        "\t\tchanDim = -1\r\n",
        "\r\n",
        "\t\t# if we are using \"channels first\", update the input shape\r\n",
        "\t\t# and channels dimension\r\n",
        "\t\tif K.image_data_format() == \"channels_first\":\r\n",
        "\t\t\tinputShape = (depth, height, width)\r\n",
        "\t\t\tchanDim = 1\r\n",
        "\r\n",
        "\t\t# define the model input and first CONV module\r\n",
        "\t\tinputs = Input(shape=inputShape)\r\n",
        "\t\tx = MiniGoogLeNet.conv_module(inputs, 96, 3, 3, (1, 1),\r\n",
        "\t\t\tchanDim)\r\n",
        "\r\n",
        "\t\t# two Inception modules followed by a downsample module\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 32, 32, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 32, 48, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.downsample_module(x, 80, chanDim)\r\n",
        "\r\n",
        "\t\t# four Inception modules followed by a downsample module\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 112, 48, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 96, 64, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 80, 80, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 48, 96, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.downsample_module(x, 96, chanDim)\r\n",
        "\r\n",
        "\t\t# two Inception modules followed by global POOL and dropout\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 176, 160, chanDim)\r\n",
        "\t\tx = MiniGoogLeNet.inception_module(x, 176, 160, chanDim)\r\n",
        "\t\tx = AveragePooling2D((7, 7))(x)\r\n",
        "\t\tx = Dropout(0.5)(x)\r\n",
        "\r\n",
        "\t\t# softmax classifier\r\n",
        "\t\tx = Flatten()(x)\r\n",
        "\t\tx = Dense(classes)(x)\r\n",
        "\t\tx = Activation(\"softmax\")(x)\r\n",
        "\r\n",
        "\t\t# create the model\r\n",
        "\t\tmodel = Model(inputs, x, name=\"googlenet\")\r\n",
        "\r\n",
        "\t\t# return the constructed network architecture\r\n",
        "\t\treturn model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gVua4L6e5ym"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.callbacks import BaseLogger\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import os\r\n",
        "\r\n",
        "class TrainingMonitor(BaseLogger):\r\n",
        "\tdef __init__(self, figPath, jsonPath=None, startAt=0):\r\n",
        "\t\t# store the output path for the figure, the path to the JSON\r\n",
        "\t\t# serialized file, and the starting epoch\r\n",
        "\t\tsuper(TrainingMonitor, self).__init__()\r\n",
        "\t\tself.figPath = figPath\r\n",
        "\t\tself.jsonPath = jsonPath\r\n",
        "\t\tself.startAt = startAt\r\n",
        "\r\n",
        "\tdef on_train_begin(self, logs={}):\r\n",
        "\t\t# initialize the history dictionary\r\n",
        "\t\tself.H = {}\r\n",
        "\r\n",
        "\t\t# if the JSON history path exists, load the training history\r\n",
        "\t\tif self.jsonPath is not None:\r\n",
        "\t\t\tif os.path.exists(self.jsonPath):\r\n",
        "\t\t\t\tself.H = json.loads(open(self.jsonPath).read())\r\n",
        "\r\n",
        "\t\t\t\t# check to see if a starting epoch was supplied\r\n",
        "\t\t\t\tif self.startAt > 0:\r\n",
        "\t\t\t\t\t# loop over the entries in the history log and\r\n",
        "\t\t\t\t\t# trim any entries that are past the starting\r\n",
        "\t\t\t\t\t# epoch\r\n",
        "\t\t\t\t\tfor k in self.H.keys():\r\n",
        "\t\t\t\t\t\tself.H[k] = self.H[k][:self.startAt]\r\n",
        "\r\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\r\n",
        "\t\t# loop over the logs and update the loss, accuracy, etc.\r\n",
        "\t\t# for the entire training process\r\n",
        "\t\tfor (k, v) in logs.items():\r\n",
        "\t\t\tl = self.H.get(k, [])\r\n",
        "\t\t\tl.append(float(v))\r\n",
        "\t\t\tself.H[k] = l\r\n",
        "\r\n",
        "\t\t# check to see if the training history should be serialized\r\n",
        "\t\t# to file\r\n",
        "\t\tif self.jsonPath is not None:\r\n",
        "\t\t\tf = open(self.jsonPath, \"w\")\r\n",
        "\t\t\tf.write(json.dumps(self.H))\r\n",
        "\t\t\tf.close()\r\n",
        "\r\n",
        "\t\t# ensure at least two epochs have passed before plotting\r\n",
        "\t\t# (epoch starts at zero)\r\n",
        "\t\tif len(self.H[\"loss\"]) > 1:\r\n",
        "\t\t\t# plot the training loss and accuracy\r\n",
        "\t\t\tN = np.arange(0, len(self.H[\"loss\"]))\r\n",
        "\t\t\tplt.style.use(\"ggplot\")\r\n",
        "\t\t\tplt.figure()\r\n",
        "\t\t\tplt.plot(N, self.H[\"loss\"], label=\"train_loss\")\r\n",
        "\t\t\tplt.plot(N, self.H[\"val_loss\"], label=\"val_loss\")\r\n",
        "\t\t\tplt.plot(N, self.H[\"accuracy\"], label=\"train_acc\")\r\n",
        "\t\t\tplt.plot(N, self.H[\"val_accuracy\"], label=\"val_acc\")\r\n",
        "\t\t\tplt.title(\"Training Loss and Accuracy [Epoch {}]\".format(\r\n",
        "\t\t\t\tlen(self.H[\"loss\"])))\r\n",
        "\t\t\tplt.xlabel(\"Epoch #\")\r\n",
        "\t\t\tplt.ylabel(\"Loss/Accuracy\")\r\n",
        "\t\t\tplt.legend()\r\n",
        "\r\n",
        "\t\t\t# save the figure\r\n",
        "\t\t\tplt.savefig(self.figPath)\r\n",
        "\t\t\tplt.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpcGw3FEeuso"
      },
      "source": [
        "# import the necessary packages\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\r\n",
        "from tensorflow.keras.optimizers import SGD\r\n",
        "from tensorflow.keras.datasets import cifar10\r\n",
        "import numpy as np\r\n",
        "import argparse\r\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbsqWySaeoaG"
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\r\n",
        "import matplotlib\r\n",
        "matplotlib.use(\"Agg\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNycW6lceruW"
      },
      "source": [
        "# definine the total number of epochs to train for along with the\r\n",
        "# initial learning rate\r\n",
        "NUM_EPOCHS = 70\r\n",
        "INIT_LR = 5e-3"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elmgLY8UesaG"
      },
      "source": [
        "def poly_decay(epoch):\r\n",
        "\t# initialize the maximum number of epochs, base learning rate,\r\n",
        "\t# and power of the polynomial\r\n",
        "\tmaxEpochs = NUM_EPOCHS\r\n",
        "\tbaseLR = INIT_LR\r\n",
        "\tpower = 1.0\r\n",
        "\r\n",
        "\t# compute the new learning rate based on polynomial decay\r\n",
        "\talpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\r\n",
        "\r\n",
        "\t# return the new learning rate\r\n",
        "\treturn alpha"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBvUUGjEfCfq",
        "outputId": "e8318f7b-748a-44d5-aadc-fb11106d7960"
      },
      "source": [
        "# load the training and testing data, converting the images from\r\n",
        "# integers to floats\r\n",
        "print(\"[INFO] loading CIFAR-10 data...\")\r\n",
        "((trainX, trainY), (testX, testY)) = cifar10.load_data()\r\n",
        "trainX = trainX.astype(\"float\")\r\n",
        "testX = testX.astype(\"float\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading CIFAR-10 data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28yfuniHfLi7"
      },
      "source": [
        "# apply mean subtraction to the data\r\n",
        "mean = np.mean(trainX, axis=0)\r\n",
        "trainX -= mean\r\n",
        "testX -= mean"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUnpOoz_fNno"
      },
      "source": [
        "# convert the labels from integers to vectors\r\n",
        "lb = LabelBinarizer()\r\n",
        "trainY = lb.fit_transform(trainY)\r\n",
        "testY = lb.transform(testY)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8MPnl6bfP2p"
      },
      "source": [
        "# construct the image generator for data augmentation\r\n",
        "aug = ImageDataGenerator(width_shift_range=0.1,\r\n",
        "\theight_shift_range=0.1, horizontal_flip=True,\r\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhSOD7XofYs3"
      },
      "source": [
        "# construct the set of callbacks\r\n",
        "figPath = os.path.sep.join([\"/content/sample_data/output\", \"{}.png\".format(os.getpid())])\r\n",
        "jsonPath = os.path.sep.join([\"/content/sample_data/output\", \"{}.json\".format(os.getpid())])\r\n",
        "\r\n",
        "callbacks = [TrainingMonitor(figPath, jsonPath=jsonPath),LearningRateScheduler(poly_decay)]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfpsKDfbfarX",
        "outputId": "41692484-8e54-495b-bd0b-2cf58a98144b"
      },
      "source": [
        "# initialize the optimizer and model\r\n",
        "print(\"[INFO] compiling model...\")\r\n",
        "opt = SGD(lr=INIT_LR, momentum=0.9)\r\n",
        "model = MiniGoogLeNet.build(width=32, height=32, depth=3, classes=10)\r\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\tmetrics=[\"accuracy\"])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy6Jg6psfdU5",
        "outputId": "40456e3a-2db6-488c-e71a-f5bbcbd542d5"
      },
      "source": [
        "# train the network\r\n",
        "print(\"[INFO] training network...\")\r\n",
        "model.fit_generator(aug.flow(trainX, trainY, batch_size=64),validation_data=(testX, testY), steps_per_epoch=len(trainX) // 64,epochs=NUM_EPOCHS, callbacks=callbacks, verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n",
            "WARNING:tensorflow:From <ipython-input-14-35c7be4d18f6>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/70\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 1.4975 - accuracy: 0.4495 - val_loss: 1.2383 - val_accuracy: 0.5512\n",
            "Epoch 2/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 1.0817 - accuracy: 0.6156 - val_loss: 1.3458 - val_accuracy: 0.5761\n",
            "Epoch 3/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.9087 - accuracy: 0.6796 - val_loss: 1.1946 - val_accuracy: 0.6179\n",
            "Epoch 4/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.7919 - accuracy: 0.7234 - val_loss: 0.9512 - val_accuracy: 0.6872\n",
            "Epoch 5/70\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.7101 - accuracy: 0.7528 - val_loss: 0.8197 - val_accuracy: 0.7258\n",
            "Epoch 6/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.6516 - accuracy: 0.7747 - val_loss: 0.8783 - val_accuracy: 0.7219\n",
            "Epoch 7/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5966 - accuracy: 0.7959 - val_loss: 0.8848 - val_accuracy: 0.7047\n",
            "Epoch 8/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5589 - accuracy: 0.8079 - val_loss: 0.8736 - val_accuracy: 0.7229\n",
            "Epoch 9/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5206 - accuracy: 0.8225 - val_loss: 0.7012 - val_accuracy: 0.7788\n",
            "Epoch 10/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4857 - accuracy: 0.8328 - val_loss: 0.7482 - val_accuracy: 0.7773\n",
            "Epoch 11/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4642 - accuracy: 0.8411 - val_loss: 0.6435 - val_accuracy: 0.7851\n",
            "Epoch 12/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.4405 - accuracy: 0.8498 - val_loss: 0.5851 - val_accuracy: 0.8057\n",
            "Epoch 13/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4137 - accuracy: 0.8581 - val_loss: 0.5365 - val_accuracy: 0.8179\n",
            "Epoch 14/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4028 - accuracy: 0.8621 - val_loss: 0.5296 - val_accuracy: 0.8220\n",
            "Epoch 15/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3781 - accuracy: 0.8695 - val_loss: 0.4857 - val_accuracy: 0.8400\n",
            "Epoch 16/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3607 - accuracy: 0.8765 - val_loss: 0.5700 - val_accuracy: 0.8184\n",
            "Epoch 17/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.3452 - accuracy: 0.8816 - val_loss: 0.5013 - val_accuracy: 0.8385\n",
            "Epoch 18/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.3333 - accuracy: 0.8841 - val_loss: 0.5078 - val_accuracy: 0.8292\n",
            "Epoch 19/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.3131 - accuracy: 0.8926 - val_loss: 0.4808 - val_accuracy: 0.8415\n",
            "Epoch 20/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3032 - accuracy: 0.8969 - val_loss: 0.5143 - val_accuracy: 0.8416\n",
            "Epoch 21/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.2909 - accuracy: 0.9007 - val_loss: 0.5583 - val_accuracy: 0.8214\n",
            "Epoch 22/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2770 - accuracy: 0.9036 - val_loss: 0.4847 - val_accuracy: 0.8490\n",
            "Epoch 23/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2714 - accuracy: 0.9064 - val_loss: 0.5446 - val_accuracy: 0.8354\n",
            "Epoch 24/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2608 - accuracy: 0.9103 - val_loss: 0.4755 - val_accuracy: 0.8510\n",
            "Epoch 25/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2481 - accuracy: 0.9148 - val_loss: 0.6534 - val_accuracy: 0.8016\n",
            "Epoch 26/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2440 - accuracy: 0.9150 - val_loss: 0.5869 - val_accuracy: 0.8270\n",
            "Epoch 27/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2336 - accuracy: 0.9194 - val_loss: 0.4221 - val_accuracy: 0.8658\n",
            "Epoch 28/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.2192 - accuracy: 0.9247 - val_loss: 0.4601 - val_accuracy: 0.8595\n",
            "Epoch 29/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.2148 - accuracy: 0.9272 - val_loss: 0.4336 - val_accuracy: 0.8602\n",
            "Epoch 30/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.2075 - accuracy: 0.9268 - val_loss: 0.4931 - val_accuracy: 0.8567\n",
            "Epoch 31/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.1976 - accuracy: 0.9326 - val_loss: 0.4177 - val_accuracy: 0.8720\n",
            "Epoch 32/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.1910 - accuracy: 0.9343 - val_loss: 0.3981 - val_accuracy: 0.8776\n",
            "Epoch 33/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.1839 - accuracy: 0.9362 - val_loss: 0.3977 - val_accuracy: 0.8755\n",
            "Epoch 34/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.1824 - accuracy: 0.9362 - val_loss: 0.3802 - val_accuracy: 0.8808\n",
            "Epoch 35/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.1714 - accuracy: 0.9406 - val_loss: 0.4095 - val_accuracy: 0.8752\n",
            "Epoch 36/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.1638 - accuracy: 0.9431 - val_loss: 0.4106 - val_accuracy: 0.8748\n",
            "Epoch 37/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.1621 - accuracy: 0.9431 - val_loss: 0.4672 - val_accuracy: 0.8655\n",
            "Epoch 38/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.1549 - accuracy: 0.9466 - val_loss: 0.4297 - val_accuracy: 0.8746\n",
            "Epoch 39/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.1500 - accuracy: 0.9482 - val_loss: 0.4328 - val_accuracy: 0.8755\n",
            "Epoch 40/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.1442 - accuracy: 0.9501 - val_loss: 0.4430 - val_accuracy: 0.8725\n",
            "Epoch 41/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.1396 - accuracy: 0.9523 - val_loss: 0.4321 - val_accuracy: 0.8742\n",
            "Epoch 42/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.1319 - accuracy: 0.9545 - val_loss: 0.3990 - val_accuracy: 0.8791\n",
            "Epoch 43/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.1257 - accuracy: 0.9570 - val_loss: 0.4187 - val_accuracy: 0.8785\n",
            "Epoch 44/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.1219 - accuracy: 0.9582 - val_loss: 0.3829 - val_accuracy: 0.8881\n",
            "Epoch 45/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.1199 - accuracy: 0.9583 - val_loss: 0.3782 - val_accuracy: 0.8901\n",
            "Epoch 46/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.1143 - accuracy: 0.9606 - val_loss: 0.4702 - val_accuracy: 0.8745\n",
            "Epoch 47/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.1078 - accuracy: 0.9626 - val_loss: 0.5318 - val_accuracy: 0.8578\n",
            "Epoch 48/70\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.1039 - accuracy: 0.9647 - val_loss: 0.4336 - val_accuracy: 0.8754\n",
            "Epoch 49/70\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.1029 - accuracy: 0.9655 - val_loss: 0.4617 - val_accuracy: 0.8735\n",
            "Epoch 50/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.1001 - accuracy: 0.9658 - val_loss: 0.3870 - val_accuracy: 0.8901\n",
            "Epoch 51/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.0974 - accuracy: 0.9678 - val_loss: 0.4350 - val_accuracy: 0.8793\n",
            "Epoch 52/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.0895 - accuracy: 0.9691 - val_loss: 0.3911 - val_accuracy: 0.8874\n",
            "Epoch 53/70\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.0873 - accuracy: 0.9701 - val_loss: 0.3882 - val_accuracy: 0.8924\n",
            "Epoch 54/70\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.0830 - accuracy: 0.9725 - val_loss: 0.4043 - val_accuracy: 0.8929\n",
            "Epoch 55/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.0788 - accuracy: 0.9732 - val_loss: 0.3819 - val_accuracy: 0.8941\n",
            "Epoch 56/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.0770 - accuracy: 0.9738 - val_loss: 0.3971 - val_accuracy: 0.8933\n",
            "Epoch 57/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.0755 - accuracy: 0.9752 - val_loss: 0.3882 - val_accuracy: 0.8915\n",
            "Epoch 58/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.0719 - accuracy: 0.9759 - val_loss: 0.4033 - val_accuracy: 0.8925\n",
            "Epoch 59/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.0688 - accuracy: 0.9772 - val_loss: 0.3897 - val_accuracy: 0.8924\n",
            "Epoch 60/70\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.0661 - accuracy: 0.9781 - val_loss: 0.3652 - val_accuracy: 0.9003\n",
            "Epoch 61/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.0639 - accuracy: 0.9794 - val_loss: 0.3721 - val_accuracy: 0.8986\n",
            "Epoch 62/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.0613 - accuracy: 0.9796 - val_loss: 0.3732 - val_accuracy: 0.9005\n",
            "Epoch 63/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.0613 - accuracy: 0.9803 - val_loss: 0.3667 - val_accuracy: 0.9002\n",
            "Epoch 64/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.0581 - accuracy: 0.9808 - val_loss: 0.3752 - val_accuracy: 0.8979\n",
            "Epoch 65/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.0578 - accuracy: 0.9811 - val_loss: 0.3705 - val_accuracy: 0.9009\n",
            "Epoch 66/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.0528 - accuracy: 0.9825 - val_loss: 0.3748 - val_accuracy: 0.8999\n",
            "Epoch 67/70\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.0532 - accuracy: 0.9833 - val_loss: 0.3643 - val_accuracy: 0.9009\n",
            "Epoch 68/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 0.3644 - val_accuracy: 0.9006\n",
            "Epoch 69/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.0503 - accuracy: 0.9840 - val_loss: 0.3601 - val_accuracy: 0.9012\n",
            "Epoch 70/70\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.0489 - accuracy: 0.9843 - val_loss: 0.3573 - val_accuracy: 0.9019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f48901be908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBR2YSKOff2m"
      },
      "source": [
        "# save the network to disk\r\n",
        "print(\"[INFO] serializing network...\")\r\n",
        "model.save(\"/content/sample_data/output/minigooglenet_cifar10.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOzmFTWUhuNt"
      },
      "source": [
        ""
      ]
    }
  ]
}